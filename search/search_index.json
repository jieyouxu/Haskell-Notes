{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Haskell Notes \u00b6 Some notes on Haskell based on Haskell Programming from First Principles .","title":"Home"},{"location":"#haskell-notes","text":"Some notes on Haskell based on Haskell Programming from First Principles .","title":"Haskell Notes"},{"location":"1-foundation/notes/","text":"Foundations \u00b6 A calculus is a method of calculating or reasoning . Lambda calculus formalizes effective computability . Functional Programming \u00b6 Functional programming (FP) is a programming paradigm relying on functions modeled on mathematical functions . Programs in FP are composed from expressions , which can be: Values ; Variables ; Functions . Functions are expressions which are applied to an argument / input , which can be reduced or evaluated . Functions are first-class in Haskell, such that they can be used as: Values ; Passed as arguments / inputs to other functions. Purity in FP can mean referential transparency : Given a function f f , if it is given the same input x x , it will always return the same output y y , like a mathematical function. Abstraction allows writing shorter code by extracting common/repeated constructs into more reusable, generic code. High levels of abstraction allows programmers to compose programs from separate functions. Functions \u00b6 A function is the relation between a set of possible inputs and a set of possible outputs . Function application maps input(s) to an output. Example Given some function f f , with the input set ( domain ) \\{ 1, 2, 3 \\} \\{ 1, 2, 3 \\} and the output set ( codomain ) \\{ A, B, C \\} \\{ A, B, C \\} , with f f defined as \\begin{aligned} f(1) &= A \\\\ f(2) &= B \\\\ f(3) &= C \\\\ \\end{aligned} \\begin{aligned} f(1) &= A \\\\ f(2) &= B \\\\ f(3) &= C \\\\ \\end{aligned} Then f f is referentially transparent \u2014 for instance, when f f receives input 1 1 it always outputs A A . This ensures that the function is in fact predictable . Note For OOP languages like Java, objects often constitute of shared mutable state. This can make testing and debugging very difficult because for some input, a method on an object does not necessarily return the same output. The previous example only defined a mapping, but not necessarily a relationship between its input and output. Example Given some function f f , let it be defined as f(x) = \\underbrace{x + 1}_{\\text{function body}} f(x) = \\underbrace{x + 1}_{\\text{function body}} The function f f takes a single named argument x x . f f describes the relationship between the input x x and output (which is described in the function body ). Upon applying the function f f , we substitute its argument x x for a concrete value, for instance 1 1 . Then f(1) = 1 + 1 = 2 f(1) = 1 + 1 = 2 . This establishes a mapping f(1) \\mapsto 2 f(1) \\mapsto 2 . Structure of Lambda Calculus \u00b6 The lambda calculus comprises three lambda terms : Expressions Variables Abstractions An expression is either one of the three lambda terms or a combination of them (hence an inductive definition). The simplest expression is a single variable, which has no meaning or value and are simply placeholder names for inputs. An abstraction is a function ; it has A head (a lambda ) A body And is applied to an argument , which is an input value. Hereafter a lambda abstraction will be referred to as a \" lambda \" or an \" abstraction \" for brevity. Abstraction An abstraction is built from a head and a body . The head of a function is a \\lambda \\lambda followed by a variable name. The body is another expression . Simple abstraction \\lambda x \\ldotp x \\lambda x \\ldotp x The variable x x named in the head is the abstraction's parameter which binds all occurrences of x x in the body. When the abstraction is applied with an input value v v given to x x , all occurrences of x x in the body takes on that input value v v . In the abstraction, the \\lambda x \\lambda x part is the head , the x x in the head is the single parameter , and the x x to the right of the \\ldotp \\ldotp is the body. Note that the x x in the body is bound by the parameter of the same name. The dot \\ldotp \\ldotp acts as a separator. Anonymous function The previous example's lambda abstraction \\lambda x \\ldotp x \\lambda x \\ldotp x does not have a name, hence it is anonymous . Hence it cannot be called by name. It is called an abstraction since it is a generalization of a concrete problem, and names given to it allows abstraction \u2014 abstracting away from tiny details to simplify the cognitive burden and facilitates code reuse. By using named variables, we can reuse the abstraction for potentially many instances of similar problems. Alpha Equivalence \u00b6 For some lambda abstraction such as \\lambda x \\ldotp x \\lambda x \\ldotp x The named variable x x has no semantic meaning apart from being a placeholder for input values. Hence, it might as well be a a or b b or c c , etc. This means that the lambda terms \\lambda x \\ldotp x \\Leftrightarrow \\lambda y \\ldotp y \\Leftrightarrow \\lambda \\beta \\ldotp \\beta \\lambda x \\ldotp x \\Leftrightarrow \\lambda y \\ldotp y \\Leftrightarrow \\lambda \\beta \\ldotp \\beta Have alpba equivalence \u2014 they are the same function. Beta Reduction \u00b6 Upon applying a function to an argument, all occurrences of the bound variable within the body (that is the parameter) are substituted with the input expression. The head can safely be eliminated as it only serves the purpose of binding a name to the parameter. Example For the abstraction \\lambda x \\ldotp x \\lambda x \\ldotp x If the abstraction is applied to 2 2 , then: Substitute 2 2 for every occurrence of x x in the body. Eliminate the head. That is, \\begin{aligned} (\\lambda x \\ldotp x)\\ 2 & \\\\ 2 & \\\\ \\end{aligned} \\begin{aligned} (\\lambda x \\ldotp x)\\ 2 & \\\\ 2 & \\\\ \\end{aligned} Identity function The previous example function \\lambda x \\ldotp x \\lambda x \\ldotp x is the identity function since it simply returns whatever input expression was given to it. This is like f(x) = x f(x) = x . To denote precedence, let parentheses () () be used to group the body expression of an abstraction. Parentheses showing precedence (\\lambda x \\ldotp x + 1) (\\lambda x \\ldotp x + 1) Here the body expression is x + 1 x + 1 . A lambda abstraction can also be applied to another lambda abstraction. Square brackets [] [] shall be used to denote substitution. Square brackets showing substitution \\newcommand{\\coloneq}{\\mathrel{\\vcenter{:}}=} \\begin{aligned} (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) & \\\\ [x \\coloneq (\\lambda y \\ldotp y)] & \\\\ (\\lambda y \\ldotp y) & \\\\ \\end{aligned} \\newcommand{\\coloneq}{\\mathrel{\\vcenter{:}}=} \\begin{aligned} (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) & \\\\ [x \\coloneq (\\lambda y \\ldotp y)] & \\\\ (\\lambda y \\ldotp y) & \\\\ \\end{aligned} Associativity of application Applications in lambda calculus are left associative from the right to the left. Left associativity of lambda application (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) z \\Leftrightarrow ((\\lambda x \\ldotp x)(\\lambda y \\ldotp y))z (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) z \\Leftrightarrow ((\\lambda x \\ldotp x)(\\lambda y \\ldotp y))z This expression may be reduced as \\newcommand{\\coloneq}{\\mathrel{\\vcenter{:}}=} \\begin{aligned} (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) z & \\\\ [x \\coloneq (\\lambda y \\ldotp y)] & \\\\ (\\lambda y \\ldotp y) z \\\\ [y \\coloneq z] \\\\ z \\end{aligned} \\newcommand{\\coloneq}{\\mathrel{\\vcenter{:}}=} \\begin{aligned} (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) z & \\\\ [x \\coloneq (\\lambda y \\ldotp y)] & \\\\ (\\lambda y \\ldotp y) z \\\\ [y \\coloneq z] \\\\ z \\end{aligned} Free Variables \u00b6 The head of an lambda abstraction provides information on which named variable is bounded to be in scope when the function is applied. Those variables in the expression body which are not named in the head are free variables . Free variable In the lambda abstraction \\lambda x \\ldotp x y \\lambda x \\ldotp x y y y is a free variable as it is not named in the head. It cannot be reduced when the function is applied to an argument. Applying lambda abstraction to a variable The lambda abstraction \\lambda x \\ldotp x y \\lambda x \\ldotp x y Can be applied to some variable z z (\\lambda x \\ldotp x y) z (\\lambda x \\ldotp x y) z . The lambda can be applied to the argument z z . (\\lambda [x \\coloneq z] \\ldotp x y) (\\lambda [x \\coloneq z] \\ldotp x y) . x x is the bound variable and its instances shall be replaced by z z , with the head being eliminated. z y z y . Head was eliminated and no more heads are left, and since z z and y y are free variables no further reductions may be applied. Multiple Arguments \u00b6 Each lambda may have only one parameter and thus can only accept one argument. Should an expression require multiple arguments, it must be composed from multiple nested heads. When such composite lambda is applied once, the leftmost/ outmost head is first eliminated, and the next is then applied. Such method of having nested heads is termed currying . Currying An abstraction such as \\lambda x y \\ldotp x y \\lambda x y \\ldotp x y Is shorthand for \\lambda x \\ldotp (\\lambda y \\ldotp x y) \\lambda x \\ldotp (\\lambda y \\ldotp x y) When the first argument x x is applied, x x is bound and the outer lambda is eliminated to become \\lambda y \\ldotp x y \\lambda y \\ldotp x y with some applied x x value. Reduction of a multi-argument lambda Let \\lambda x y \\ldotp x y \\lambda x y \\ldotp x y Be applied to 1 1 and 2 2 respectively. Then \\begin{aligned} (\\lambda x y \\ldotp x y)\\ 1\\ 2 & \\\\ (\\lambda x \\ldotp (\\lambda y \\ldotp x y))\\ 1\\ 2 & \\\\ [x \\coloneq 1] & \\\\ (\\lambda y \\ldotp 1 y)\\ 2 & \\\\ [y \\coloneq 2] & \\\\ 1\\ 2 & \\\\ \\end{aligned} \\begin{aligned} (\\lambda x y \\ldotp x y)\\ 1\\ 2 & \\\\ (\\lambda x \\ldotp (\\lambda y \\ldotp x y))\\ 1\\ 2 & \\\\ [x \\coloneq 1] & \\\\ (\\lambda y \\ldotp 1 y)\\ 2 & \\\\ [y \\coloneq 2] & \\\\ 1\\ 2 & \\\\ \\end{aligned} Beta Normal Form \u00b6 A beta normal form (BNF) is when some lambda expression cannot be beta reduced any further - a fully evaluated expression or program. Combinator \u00b6 A combinator is a lambda term with no free variables, and only serve to combine given arguments. Valid combinators \\lambda x \\ldotp x \\lambda x \\ldotp x x x is the only variable and is bound. \\lambda x y \\ldotp x \\lambda x y \\ldotp x \\lambda x y z \\ldotp x z (y z) \\lambda x y z \\ldotp x z (y z) Not combinators \\lambda y \\ldotp x \\lambda y \\ldotp x x x is a free variable. \\lambda x \\ldotp x z \\lambda x \\ldotp x z z z is a free variable. Divergence \u00b6 Some lambda terms do not reduce to a beta normal form because they diverge . Divergence refers to the evaluation process never terminates. Omega lambda term (diverging) (\\lambda x \\ldotp x x)(\\lambda x \\ldotp x x) (\\lambda x \\ldotp x x)(\\lambda x \\ldotp x x) x x in first lambda's head becomes second lambda. ([x \\coloneq (\\lambda x \\ldotp x x)]) x x ([x \\coloneq (\\lambda x \\ldotp x x)]) x x (\\lambda x \\ldotp x x)(\\lambda x \\ldotp x x) (\\lambda x \\ldotp x x)(\\lambda x \\ldotp x x) Substitution of (\\lambda x \\ldotp x x) (\\lambda x \\ldotp x x) for x x causes the original lambda to reappear and thus evaluation cannot terminate.","title":"Foundation"},{"location":"1-foundation/notes/#foundations","text":"A calculus is a method of calculating or reasoning . Lambda calculus formalizes effective computability .","title":"Foundations"},{"location":"1-foundation/notes/#functional-programming","text":"Functional programming (FP) is a programming paradigm relying on functions modeled on mathematical functions . Programs in FP are composed from expressions , which can be: Values ; Variables ; Functions . Functions are expressions which are applied to an argument / input , which can be reduced or evaluated . Functions are first-class in Haskell, such that they can be used as: Values ; Passed as arguments / inputs to other functions. Purity in FP can mean referential transparency : Given a function f f , if it is given the same input x x , it will always return the same output y y , like a mathematical function. Abstraction allows writing shorter code by extracting common/repeated constructs into more reusable, generic code. High levels of abstraction allows programmers to compose programs from separate functions.","title":"Functional Programming"},{"location":"1-foundation/notes/#functions","text":"A function is the relation between a set of possible inputs and a set of possible outputs . Function application maps input(s) to an output. Example Given some function f f , with the input set ( domain ) \\{ 1, 2, 3 \\} \\{ 1, 2, 3 \\} and the output set ( codomain ) \\{ A, B, C \\} \\{ A, B, C \\} , with f f defined as \\begin{aligned} f(1) &= A \\\\ f(2) &= B \\\\ f(3) &= C \\\\ \\end{aligned} \\begin{aligned} f(1) &= A \\\\ f(2) &= B \\\\ f(3) &= C \\\\ \\end{aligned} Then f f is referentially transparent \u2014 for instance, when f f receives input 1 1 it always outputs A A . This ensures that the function is in fact predictable . Note For OOP languages like Java, objects often constitute of shared mutable state. This can make testing and debugging very difficult because for some input, a method on an object does not necessarily return the same output. The previous example only defined a mapping, but not necessarily a relationship between its input and output. Example Given some function f f , let it be defined as f(x) = \\underbrace{x + 1}_{\\text{function body}} f(x) = \\underbrace{x + 1}_{\\text{function body}} The function f f takes a single named argument x x . f f describes the relationship between the input x x and output (which is described in the function body ). Upon applying the function f f , we substitute its argument x x for a concrete value, for instance 1 1 . Then f(1) = 1 + 1 = 2 f(1) = 1 + 1 = 2 . This establishes a mapping f(1) \\mapsto 2 f(1) \\mapsto 2 .","title":"Functions"},{"location":"1-foundation/notes/#structure-of-lambda-calculus","text":"The lambda calculus comprises three lambda terms : Expressions Variables Abstractions An expression is either one of the three lambda terms or a combination of them (hence an inductive definition). The simplest expression is a single variable, which has no meaning or value and are simply placeholder names for inputs. An abstraction is a function ; it has A head (a lambda ) A body And is applied to an argument , which is an input value. Hereafter a lambda abstraction will be referred to as a \" lambda \" or an \" abstraction \" for brevity. Abstraction An abstraction is built from a head and a body . The head of a function is a \\lambda \\lambda followed by a variable name. The body is another expression . Simple abstraction \\lambda x \\ldotp x \\lambda x \\ldotp x The variable x x named in the head is the abstraction's parameter which binds all occurrences of x x in the body. When the abstraction is applied with an input value v v given to x x , all occurrences of x x in the body takes on that input value v v . In the abstraction, the \\lambda x \\lambda x part is the head , the x x in the head is the single parameter , and the x x to the right of the \\ldotp \\ldotp is the body. Note that the x x in the body is bound by the parameter of the same name. The dot \\ldotp \\ldotp acts as a separator. Anonymous function The previous example's lambda abstraction \\lambda x \\ldotp x \\lambda x \\ldotp x does not have a name, hence it is anonymous . Hence it cannot be called by name. It is called an abstraction since it is a generalization of a concrete problem, and names given to it allows abstraction \u2014 abstracting away from tiny details to simplify the cognitive burden and facilitates code reuse. By using named variables, we can reuse the abstraction for potentially many instances of similar problems.","title":"Structure of Lambda Calculus"},{"location":"1-foundation/notes/#alpha-equivalence","text":"For some lambda abstraction such as \\lambda x \\ldotp x \\lambda x \\ldotp x The named variable x x has no semantic meaning apart from being a placeholder for input values. Hence, it might as well be a a or b b or c c , etc. This means that the lambda terms \\lambda x \\ldotp x \\Leftrightarrow \\lambda y \\ldotp y \\Leftrightarrow \\lambda \\beta \\ldotp \\beta \\lambda x \\ldotp x \\Leftrightarrow \\lambda y \\ldotp y \\Leftrightarrow \\lambda \\beta \\ldotp \\beta Have alpba equivalence \u2014 they are the same function.","title":"Alpha Equivalence"},{"location":"1-foundation/notes/#beta-reduction","text":"Upon applying a function to an argument, all occurrences of the bound variable within the body (that is the parameter) are substituted with the input expression. The head can safely be eliminated as it only serves the purpose of binding a name to the parameter. Example For the abstraction \\lambda x \\ldotp x \\lambda x \\ldotp x If the abstraction is applied to 2 2 , then: Substitute 2 2 for every occurrence of x x in the body. Eliminate the head. That is, \\begin{aligned} (\\lambda x \\ldotp x)\\ 2 & \\\\ 2 & \\\\ \\end{aligned} \\begin{aligned} (\\lambda x \\ldotp x)\\ 2 & \\\\ 2 & \\\\ \\end{aligned} Identity function The previous example function \\lambda x \\ldotp x \\lambda x \\ldotp x is the identity function since it simply returns whatever input expression was given to it. This is like f(x) = x f(x) = x . To denote precedence, let parentheses () () be used to group the body expression of an abstraction. Parentheses showing precedence (\\lambda x \\ldotp x + 1) (\\lambda x \\ldotp x + 1) Here the body expression is x + 1 x + 1 . A lambda abstraction can also be applied to another lambda abstraction. Square brackets [] [] shall be used to denote substitution. Square brackets showing substitution \\newcommand{\\coloneq}{\\mathrel{\\vcenter{:}}=} \\begin{aligned} (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) & \\\\ [x \\coloneq (\\lambda y \\ldotp y)] & \\\\ (\\lambda y \\ldotp y) & \\\\ \\end{aligned} \\newcommand{\\coloneq}{\\mathrel{\\vcenter{:}}=} \\begin{aligned} (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) & \\\\ [x \\coloneq (\\lambda y \\ldotp y)] & \\\\ (\\lambda y \\ldotp y) & \\\\ \\end{aligned} Associativity of application Applications in lambda calculus are left associative from the right to the left. Left associativity of lambda application (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) z \\Leftrightarrow ((\\lambda x \\ldotp x)(\\lambda y \\ldotp y))z (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) z \\Leftrightarrow ((\\lambda x \\ldotp x)(\\lambda y \\ldotp y))z This expression may be reduced as \\newcommand{\\coloneq}{\\mathrel{\\vcenter{:}}=} \\begin{aligned} (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) z & \\\\ [x \\coloneq (\\lambda y \\ldotp y)] & \\\\ (\\lambda y \\ldotp y) z \\\\ [y \\coloneq z] \\\\ z \\end{aligned} \\newcommand{\\coloneq}{\\mathrel{\\vcenter{:}}=} \\begin{aligned} (\\lambda x \\ldotp x)(\\lambda y \\ldotp y) z & \\\\ [x \\coloneq (\\lambda y \\ldotp y)] & \\\\ (\\lambda y \\ldotp y) z \\\\ [y \\coloneq z] \\\\ z \\end{aligned}","title":"Beta Reduction"},{"location":"1-foundation/notes/#free-variables","text":"The head of an lambda abstraction provides information on which named variable is bounded to be in scope when the function is applied. Those variables in the expression body which are not named in the head are free variables . Free variable In the lambda abstraction \\lambda x \\ldotp x y \\lambda x \\ldotp x y y y is a free variable as it is not named in the head. It cannot be reduced when the function is applied to an argument. Applying lambda abstraction to a variable The lambda abstraction \\lambda x \\ldotp x y \\lambda x \\ldotp x y Can be applied to some variable z z (\\lambda x \\ldotp x y) z (\\lambda x \\ldotp x y) z . The lambda can be applied to the argument z z . (\\lambda [x \\coloneq z] \\ldotp x y) (\\lambda [x \\coloneq z] \\ldotp x y) . x x is the bound variable and its instances shall be replaced by z z , with the head being eliminated. z y z y . Head was eliminated and no more heads are left, and since z z and y y are free variables no further reductions may be applied.","title":"Free Variables"},{"location":"1-foundation/notes/#multiple-arguments","text":"Each lambda may have only one parameter and thus can only accept one argument. Should an expression require multiple arguments, it must be composed from multiple nested heads. When such composite lambda is applied once, the leftmost/ outmost head is first eliminated, and the next is then applied. Such method of having nested heads is termed currying . Currying An abstraction such as \\lambda x y \\ldotp x y \\lambda x y \\ldotp x y Is shorthand for \\lambda x \\ldotp (\\lambda y \\ldotp x y) \\lambda x \\ldotp (\\lambda y \\ldotp x y) When the first argument x x is applied, x x is bound and the outer lambda is eliminated to become \\lambda y \\ldotp x y \\lambda y \\ldotp x y with some applied x x value. Reduction of a multi-argument lambda Let \\lambda x y \\ldotp x y \\lambda x y \\ldotp x y Be applied to 1 1 and 2 2 respectively. Then \\begin{aligned} (\\lambda x y \\ldotp x y)\\ 1\\ 2 & \\\\ (\\lambda x \\ldotp (\\lambda y \\ldotp x y))\\ 1\\ 2 & \\\\ [x \\coloneq 1] & \\\\ (\\lambda y \\ldotp 1 y)\\ 2 & \\\\ [y \\coloneq 2] & \\\\ 1\\ 2 & \\\\ \\end{aligned} \\begin{aligned} (\\lambda x y \\ldotp x y)\\ 1\\ 2 & \\\\ (\\lambda x \\ldotp (\\lambda y \\ldotp x y))\\ 1\\ 2 & \\\\ [x \\coloneq 1] & \\\\ (\\lambda y \\ldotp 1 y)\\ 2 & \\\\ [y \\coloneq 2] & \\\\ 1\\ 2 & \\\\ \\end{aligned}","title":"Multiple Arguments"},{"location":"1-foundation/notes/#beta-normal-form","text":"A beta normal form (BNF) is when some lambda expression cannot be beta reduced any further - a fully evaluated expression or program.","title":"Beta Normal Form"},{"location":"1-foundation/notes/#combinator","text":"A combinator is a lambda term with no free variables, and only serve to combine given arguments. Valid combinators \\lambda x \\ldotp x \\lambda x \\ldotp x x x is the only variable and is bound. \\lambda x y \\ldotp x \\lambda x y \\ldotp x \\lambda x y z \\ldotp x z (y z) \\lambda x y z \\ldotp x z (y z) Not combinators \\lambda y \\ldotp x \\lambda y \\ldotp x x x is a free variable. \\lambda x \\ldotp x z \\lambda x \\ldotp x z z z is a free variable.","title":"Combinator"},{"location":"1-foundation/notes/#divergence","text":"Some lambda terms do not reduce to a beta normal form because they diverge . Divergence refers to the evaluation process never terminates. Omega lambda term (diverging) (\\lambda x \\ldotp x x)(\\lambda x \\ldotp x x) (\\lambda x \\ldotp x x)(\\lambda x \\ldotp x x) x x in first lambda's head becomes second lambda. ([x \\coloneq (\\lambda x \\ldotp x x)]) x x ([x \\coloneq (\\lambda x \\ldotp x x)]) x x (\\lambda x \\ldotp x x)(\\lambda x \\ldotp x x) (\\lambda x \\ldotp x x)(\\lambda x \\ldotp x x) Substitution of (\\lambda x \\ldotp x x) (\\lambda x \\ldotp x x) for x x causes the original lambda to reappear and thus evaluation cannot terminate.","title":"Divergence"},{"location":"10-folding-lists/notes/","text":"List Folding \u00b6 Folding \u00b6 Folds are called catamorphisms , which are means of deconstructing data. foldr :: Foldable t => ( a -> b -> b ) -> b -> t a -> b When specialized to lists which are instances of Foldable : foldr :: ( a -> b -> b ) -> b -> [ a ] -> b A fold replaces the cons constructors with the supplied function ( a -> b -> b ) and reduces the list. Recursion \u00b6 In the case of sum , it uses foldr internally by replacing the cons ( : ) constructors with the ( + ) operator. Many functions such as sum , length , concat , product when written in terms of themselves recursively have much structural similarity where they relied on having an initial base case, then changing the cons constructor into a different binary function. Example sum :: [ Integer ] -> Integer sum [] = 0 sum ( x : xs ) = x + sum xs length :: [ a ] -> Integer length [] = 0 length ( _ : xs ) = 1 + length xs product :: [ Integer ] -> Integer product [] = 1 product ( x : xs ) = x * product xs concat :: [[ a ]] -> [ a ] concat [] = [] concat ( x : xs ) = x ++ concat xs Notice that each base case is the identity for the binary function, with associativity to the right \u2014 head is first evaluated, then the next head, and so on. Fold Right \u00b6 foldr is right-associative. foldr :: ( a -> b -> b ) -> b -> [ a ] -> b foldr f id [] = id foldr f id ( x : xs ) = f x ( foldr f id xs ) Example foldr ( + ) 0 [ 1 , 2 , 3 ] 1 + ( 2 + ( 3 + 0 )) 1 + ( 2 + 3 ) 1 + 5 6 Folding occurs in two stages: Traversal : fold recursing the spine. Folding : reduction of folding function applied to values. All folds have same traversal direction, with the difference being in the association of the folding function and thus the direction of reduction. In the case of foldr and lazy evaluation, if f does not evaluate rest of the fold no more part of the spine will be forced to evaluate. This means that foldr can avoid evaluating not only the rest of the values, but also rest of the spine. This allows foldr to be used with potentially infinite lists. Fold Left \u00b6 foldl traverses the input list's spine in the same direction as foldr , but its folding process is left associative and thus proceeds in the opposite direction as foldr . foldl :: ( b -> a -> b ) -> b -> [ a ] -> b foldl f acc [] = acc foldl f acc ( x : xs ) = foldl f ( f acc x ) xs foldl begins its reduction process by applying the folding function to the accumulator acc value and the head value. Example foldr ( ^ ) 2 [ 1 .. 3 ] ( 1 ^ ( 2 ^ ( 3 ^ 2 ))) ( 1 ^ ( 2 ^ 9 )) ( 1 ^ 512 ) 1 foldl ( ^ ) 2 [ 1 .. 3 ] ((( 2 ^ 1 ) ^ 2 ) ^ 3 ) (( 2 ^ 2 ) ^ 3 ) ( 4 ^ 3 ) 64 Example foldr ( : ) [] [ 1 .. 3 ] [ 1 , 2 , 3 ] foldl ( flip ( : )) [] [ 1 .. 3 ] [ 3 , 2 , 1 ] flip The helper function flip can be used to change the argument order of a binary function: flip :: ( a -> b -> c ) -> b -> a -> c flip f = \\ b -> ( \\ a -> f a b ) Or parenthesized: flip :: ( a -> b -> c ) -> ( b -> a -> c ) Note that foldl has unconditional recursion of the spine since the next recursion isn't determined by the folding function. This means that it will not work for potentially infinite lists or lists which contain bottom values. Folding and Evaluation \u00b6 For finite lists, foldr and foldl is related by: foldr f z xs = foldl ( flip f ) z ( reverse xs )","title":"List Folding"},{"location":"10-folding-lists/notes/#list-folding","text":"","title":"List Folding"},{"location":"10-folding-lists/notes/#folding","text":"Folds are called catamorphisms , which are means of deconstructing data. foldr :: Foldable t => ( a -> b -> b ) -> b -> t a -> b When specialized to lists which are instances of Foldable : foldr :: ( a -> b -> b ) -> b -> [ a ] -> b A fold replaces the cons constructors with the supplied function ( a -> b -> b ) and reduces the list.","title":"Folding"},{"location":"10-folding-lists/notes/#recursion","text":"In the case of sum , it uses foldr internally by replacing the cons ( : ) constructors with the ( + ) operator. Many functions such as sum , length , concat , product when written in terms of themselves recursively have much structural similarity where they relied on having an initial base case, then changing the cons constructor into a different binary function. Example sum :: [ Integer ] -> Integer sum [] = 0 sum ( x : xs ) = x + sum xs length :: [ a ] -> Integer length [] = 0 length ( _ : xs ) = 1 + length xs product :: [ Integer ] -> Integer product [] = 1 product ( x : xs ) = x * product xs concat :: [[ a ]] -> [ a ] concat [] = [] concat ( x : xs ) = x ++ concat xs Notice that each base case is the identity for the binary function, with associativity to the right \u2014 head is first evaluated, then the next head, and so on.","title":"Recursion"},{"location":"10-folding-lists/notes/#fold-right","text":"foldr is right-associative. foldr :: ( a -> b -> b ) -> b -> [ a ] -> b foldr f id [] = id foldr f id ( x : xs ) = f x ( foldr f id xs ) Example foldr ( + ) 0 [ 1 , 2 , 3 ] 1 + ( 2 + ( 3 + 0 )) 1 + ( 2 + 3 ) 1 + 5 6 Folding occurs in two stages: Traversal : fold recursing the spine. Folding : reduction of folding function applied to values. All folds have same traversal direction, with the difference being in the association of the folding function and thus the direction of reduction. In the case of foldr and lazy evaluation, if f does not evaluate rest of the fold no more part of the spine will be forced to evaluate. This means that foldr can avoid evaluating not only the rest of the values, but also rest of the spine. This allows foldr to be used with potentially infinite lists.","title":"Fold Right"},{"location":"10-folding-lists/notes/#fold-left","text":"foldl traverses the input list's spine in the same direction as foldr , but its folding process is left associative and thus proceeds in the opposite direction as foldr . foldl :: ( b -> a -> b ) -> b -> [ a ] -> b foldl f acc [] = acc foldl f acc ( x : xs ) = foldl f ( f acc x ) xs foldl begins its reduction process by applying the folding function to the accumulator acc value and the head value. Example foldr ( ^ ) 2 [ 1 .. 3 ] ( 1 ^ ( 2 ^ ( 3 ^ 2 ))) ( 1 ^ ( 2 ^ 9 )) ( 1 ^ 512 ) 1 foldl ( ^ ) 2 [ 1 .. 3 ] ((( 2 ^ 1 ) ^ 2 ) ^ 3 ) (( 2 ^ 2 ) ^ 3 ) ( 4 ^ 3 ) 64 Example foldr ( : ) [] [ 1 .. 3 ] [ 1 , 2 , 3 ] foldl ( flip ( : )) [] [ 1 .. 3 ] [ 3 , 2 , 1 ] flip The helper function flip can be used to change the argument order of a binary function: flip :: ( a -> b -> c ) -> b -> a -> c flip f = \\ b -> ( \\ a -> f a b ) Or parenthesized: flip :: ( a -> b -> c ) -> ( b -> a -> c ) Note that foldl has unconditional recursion of the spine since the next recursion isn't determined by the folding function. This means that it will not work for potentially infinite lists or lists which contain bottom values.","title":"Fold Left"},{"location":"10-folding-lists/notes/#folding-and-evaluation","text":"For finite lists, foldr and foldl is related by: foldr f z xs = foldl ( flip f ) z ( reverse xs )","title":"Folding and Evaluation"},{"location":"11-algebraic-datatypes/notes/","text":"Algebraic Datatypes (ADTs) \u00b6 A type is an enumeration of data constructors which each have zero or more arguments. Haskell has: Sum types Product types Product types via record syntax Type aliases Newtype Data and Type Constructors \u00b6 Haskell has type constructors and data constructors : Type constructors used only at type level, signatures and typeclass declaration and instances; static and resolved at compile time. Data constructors construct values at term level; resolved at run time. Type constants refer to types which do not take additional parameters, for example Bool . data Bool = False | True Type constructors refer to types which take additional type parameters, for example Maybe a . data Maybe a = Nothing | Just a Type Constructors and Kinds \u00b6 Kinds are the types of types, represented in * . When some type is a fully applied concrete type, its kind is * . When some type is awaiting a concrete type to be supplied, it has the kind * -> * , like a function. Kind information The GHCi can provide kind information via : kind or : k . Prelude > : k Bool Bool :: * Prelude > : k [] [] :: * -> * Prelude > : k Maybe Maybe :: * -> * Notice that [] is not a concrete type since it still needs to be applied to some concrete type \u2014 hence, this is what the constructor in the name type constructor is referring to. Data Constructors and Values \u00b6 Similar to type constants and type constructors , there are also differences between data constructors and constant values. data Maybe a = Nothing | Just a Here, Maybe is a type constructor since it is awaiting a type argument a and Maybe has the kind Maybe :: * -> * . It is a sum type of an constant and a data constructor: Nothing is a constant value. Just a is a data constructor. Type vs Data \u00b6 Haskell types are static and resolved at compile time, while data are what gets passed around at run time. Haskell type information do not persist through to run time. Haskell compilation causes a phase separation to occur: Compile time: type constructors Run time: data constructors Data Constructor Arity \u00b6 Arity refers to the number of arguments a function or constructor has. Number of Arguments Adjective 0 Nullary 1 Unary 2 Binary 3 Ternary Data constructors with more than one argument is called a product type . Algebraic \u00b6 Haskell datatypes are algebraic because they can be described their argument structure using the two operations sum and product . The datatypes are called sum and product based on how their cardinality is calculated, like that of finite set theory. The cardinality of a datatype is the number of possible values that it defines, from 0 0 to possibly \\infty \\infty . If cardinality of a datatype is calculated, it is possible then to determine how many different possible implementations there are of a function for a given type. Bool The Bool type is a sum type defined by two nullary data constructors. This means that there are only two possible values for the Bool datatype: either True or False . Hence, the cardinality of Bool is 2 2 . Int8 The Int8 type can take 8-bits of data, which is 256 256 different combinations. Hence, its cardinality is 256 256 . Newtype \u00b6 The newtype keyword restricts the type declaration to a single data constructor. Hence, the cardinality of the type is exactly equivalent to the cardinality of its sole data constructor. A newtype cannot be a product type, sum type or contain nullary constructors. However, it has zero runtime overhead, as it cannot be a record (product type) or tagged union (sum type). Its presence is erased at run time. newtype allows an additional layer of differentiation in the type level, even if the underlying contained types are identical. Newtype newtype LineNumber = LineNumber Int newtype ColumnNumber = ColumnNumber Int showLineNumber :: LineNumber -> String Passing a ColumnNumber to showLineNumber causes type-checking to fail since a ColumnNumber is not a LineNumber even if their underlying type is the same Int type. If it is necessary to reuse the typeclass instance of the underlying type, one may use the GHC language extension GeneralizedNewtypeDeriving {-# LANGUAGE GeneralizedNewtypeDeriving #-} newtype LineNumber = LineNumber Int Sum Types \u00b6 To calculate the cardinality of the type built from multiple data constructors, we add the cardinalities of each data constructor. Cardinality of Bool data Bool = False | True Bool is a sum type built from two data constructors, False and True . Its cardinality is the cardinality of False ( 1 1 ) plus the cardinality of True ( 1 1 ), hence 1 + 1 = 2 1 + 1 = 2 . Product Types \u00b6 The cardinality of a product type is the product of its constituents. Cardinality of (Bool, Bool) data BB = BB ( Bool , Bool ) The cardinality of the type BB is equivalent to its sole data constructor BB , which comprises of the single argument ( Bool , Bool ) . The cardinality of ( Bool , Bool ) is the product of its two constituents, both Bool . Hence, the cardinality of ( Bool , Bool ) is 2 \\times 2 = 4 2 \\times 2 = 4 and so the cardinality of BB is also 4 4 . Record Syntax \u00b6 Compared to anonymous product type (i.e. tuples since their constituents are not named), records name each of its constitutents. data Person = Person { name :: String , age :: Int } To calculate Person 's cardinality, we first note that Person has a sole data constructor of the same name. The data constructor Person 's cardinality is further equivalent to the product of the cardinality of its two constitutents. Function Type \u00b6 For some function of type a -> b , its cardinality is the exponentiation {\\lvert b \\rvert} ^ {\\lvert a \\rvert} {\\lvert b \\rvert} ^ {\\lvert a \\rvert} . Higher-kinded Datatypes \u00b6 Kinds are not types unless fully applied to be * . Kinds such as * -> * and * -> * -> * are waiting for one and two type arguments respectively before they become types, and are known as higher-kinded types. Type arguments can be used to express \"hole\"s to be filled in. Binary Tree \u00b6 A recursive datatype is the binary tree. data BinaryTree a = Leaf | Node ( BinaryTree a ) a ( BinaryTree a ) deriving ( Eq , Ord , Show ) Insertion into a binary tree depends on ordering: insertBt :: Ord a => a -> BinaryTree a -> BinaryTree a -- Base case: create a new b-tree from an empty tree consisting of a single leaf insertBt b Leaf = Node Leaf b Leaf insertBt b ( Node left a right ) | b == a = Node left a right | b < a = Node ( insertBt b left ) a right | b > a = Node left a ( insertBt b right ) As-Pattern \u00b6 As-pattern @ allows binding a named to the destructued value. printSnd :: ( a , b ) -> IO b printSnd tuple @ ( _ , b ) = do print tuple return b","title":"Algebraic Datatypes"},{"location":"11-algebraic-datatypes/notes/#algebraic-datatypes-adts","text":"A type is an enumeration of data constructors which each have zero or more arguments. Haskell has: Sum types Product types Product types via record syntax Type aliases Newtype","title":"Algebraic Datatypes (ADTs)"},{"location":"11-algebraic-datatypes/notes/#data-and-type-constructors","text":"Haskell has type constructors and data constructors : Type constructors used only at type level, signatures and typeclass declaration and instances; static and resolved at compile time. Data constructors construct values at term level; resolved at run time. Type constants refer to types which do not take additional parameters, for example Bool . data Bool = False | True Type constructors refer to types which take additional type parameters, for example Maybe a . data Maybe a = Nothing | Just a","title":"Data and Type Constructors"},{"location":"11-algebraic-datatypes/notes/#type-constructors-and-kinds","text":"Kinds are the types of types, represented in * . When some type is a fully applied concrete type, its kind is * . When some type is awaiting a concrete type to be supplied, it has the kind * -> * , like a function. Kind information The GHCi can provide kind information via : kind or : k . Prelude > : k Bool Bool :: * Prelude > : k [] [] :: * -> * Prelude > : k Maybe Maybe :: * -> * Notice that [] is not a concrete type since it still needs to be applied to some concrete type \u2014 hence, this is what the constructor in the name type constructor is referring to.","title":"Type Constructors and Kinds"},{"location":"11-algebraic-datatypes/notes/#data-constructors-and-values","text":"Similar to type constants and type constructors , there are also differences between data constructors and constant values. data Maybe a = Nothing | Just a Here, Maybe is a type constructor since it is awaiting a type argument a and Maybe has the kind Maybe :: * -> * . It is a sum type of an constant and a data constructor: Nothing is a constant value. Just a is a data constructor.","title":"Data Constructors and Values"},{"location":"11-algebraic-datatypes/notes/#type-vs-data","text":"Haskell types are static and resolved at compile time, while data are what gets passed around at run time. Haskell type information do not persist through to run time. Haskell compilation causes a phase separation to occur: Compile time: type constructors Run time: data constructors","title":"Type vs Data"},{"location":"11-algebraic-datatypes/notes/#data-constructor-arity","text":"Arity refers to the number of arguments a function or constructor has. Number of Arguments Adjective 0 Nullary 1 Unary 2 Binary 3 Ternary Data constructors with more than one argument is called a product type .","title":"Data Constructor Arity"},{"location":"11-algebraic-datatypes/notes/#algebraic","text":"Haskell datatypes are algebraic because they can be described their argument structure using the two operations sum and product . The datatypes are called sum and product based on how their cardinality is calculated, like that of finite set theory. The cardinality of a datatype is the number of possible values that it defines, from 0 0 to possibly \\infty \\infty . If cardinality of a datatype is calculated, it is possible then to determine how many different possible implementations there are of a function for a given type. Bool The Bool type is a sum type defined by two nullary data constructors. This means that there are only two possible values for the Bool datatype: either True or False . Hence, the cardinality of Bool is 2 2 . Int8 The Int8 type can take 8-bits of data, which is 256 256 different combinations. Hence, its cardinality is 256 256 .","title":"Algebraic"},{"location":"11-algebraic-datatypes/notes/#newtype","text":"The newtype keyword restricts the type declaration to a single data constructor. Hence, the cardinality of the type is exactly equivalent to the cardinality of its sole data constructor. A newtype cannot be a product type, sum type or contain nullary constructors. However, it has zero runtime overhead, as it cannot be a record (product type) or tagged union (sum type). Its presence is erased at run time. newtype allows an additional layer of differentiation in the type level, even if the underlying contained types are identical. Newtype newtype LineNumber = LineNumber Int newtype ColumnNumber = ColumnNumber Int showLineNumber :: LineNumber -> String Passing a ColumnNumber to showLineNumber causes type-checking to fail since a ColumnNumber is not a LineNumber even if their underlying type is the same Int type. If it is necessary to reuse the typeclass instance of the underlying type, one may use the GHC language extension GeneralizedNewtypeDeriving {-# LANGUAGE GeneralizedNewtypeDeriving #-} newtype LineNumber = LineNumber Int","title":"Newtype"},{"location":"11-algebraic-datatypes/notes/#sum-types","text":"To calculate the cardinality of the type built from multiple data constructors, we add the cardinalities of each data constructor. Cardinality of Bool data Bool = False | True Bool is a sum type built from two data constructors, False and True . Its cardinality is the cardinality of False ( 1 1 ) plus the cardinality of True ( 1 1 ), hence 1 + 1 = 2 1 + 1 = 2 .","title":"Sum Types"},{"location":"11-algebraic-datatypes/notes/#product-types","text":"The cardinality of a product type is the product of its constituents. Cardinality of (Bool, Bool) data BB = BB ( Bool , Bool ) The cardinality of the type BB is equivalent to its sole data constructor BB , which comprises of the single argument ( Bool , Bool ) . The cardinality of ( Bool , Bool ) is the product of its two constituents, both Bool . Hence, the cardinality of ( Bool , Bool ) is 2 \\times 2 = 4 2 \\times 2 = 4 and so the cardinality of BB is also 4 4 .","title":"Product Types"},{"location":"11-algebraic-datatypes/notes/#record-syntax","text":"Compared to anonymous product type (i.e. tuples since their constituents are not named), records name each of its constitutents. data Person = Person { name :: String , age :: Int } To calculate Person 's cardinality, we first note that Person has a sole data constructor of the same name. The data constructor Person 's cardinality is further equivalent to the product of the cardinality of its two constitutents.","title":"Record Syntax"},{"location":"11-algebraic-datatypes/notes/#function-type","text":"For some function of type a -> b , its cardinality is the exponentiation {\\lvert b \\rvert} ^ {\\lvert a \\rvert} {\\lvert b \\rvert} ^ {\\lvert a \\rvert} .","title":"Function Type"},{"location":"11-algebraic-datatypes/notes/#higher-kinded-datatypes","text":"Kinds are not types unless fully applied to be * . Kinds such as * -> * and * -> * -> * are waiting for one and two type arguments respectively before they become types, and are known as higher-kinded types. Type arguments can be used to express \"hole\"s to be filled in.","title":"Higher-kinded Datatypes"},{"location":"11-algebraic-datatypes/notes/#binary-tree","text":"A recursive datatype is the binary tree. data BinaryTree a = Leaf | Node ( BinaryTree a ) a ( BinaryTree a ) deriving ( Eq , Ord , Show ) Insertion into a binary tree depends on ordering: insertBt :: Ord a => a -> BinaryTree a -> BinaryTree a -- Base case: create a new b-tree from an empty tree consisting of a single leaf insertBt b Leaf = Node Leaf b Leaf insertBt b ( Node left a right ) | b == a = Node left a right | b < a = Node ( insertBt b left ) a right | b > a = Node left a ( insertBt b right )","title":"Binary Tree"},{"location":"11-algebraic-datatypes/notes/#as-pattern","text":"As-pattern @ allows binding a named to the destructued value. printSnd :: ( a , b ) -> IO b printSnd tuple @ ( _ , b ) = do print tuple return b","title":"As-Pattern"},{"location":"12-handling-exceptions/notes/","text":"Handling Exceptions \u00b6 Exceptions The exceptions here refers to exceptional cases such as invalid inputs, and not Exception s in languages like Java. Exceptions and control flow Exception s in languages like Java have the problem of interfering with control flow and causes the Exception to propagate. Maybe \u00b6 The usage of Maybe can be used to signal invalid input. Smart constructor -- aliases type Name = String type Age = Int data Person = Person Name Age deriving Show A smart constructor function mkPerson :: Name -> Age -> Maybe Person can be used to allow construction of a datatype only if the inputs satisfy certain constraints. mkPerson :: Name -> Age -> Maybe Person mkPerson name age | name /= \"\" && age >= 0 = Just ( Person name age ) | otherwise = Nothing Either \u00b6 In addition to Maybe , where only a success / failure may be indicated, the datatype Either may be used to attach causes of failure. data Either a b = Left a | Right b Indicating failure causes data PersonInvalid = EmptyName | NegativeAge deriving ( Show , Eq ) mkPerson :: Name -> Age -> Either PersonInvalid Person mkPerson name age | name /= \"\" && age >= 0 = Right ( Person name age ) | name == \"\" = Left ( EmptyName ) | otherwise = Left ( NegativeAge ) Notice that the datatype occupying the Left data constructor is the error cause, while the Right data constructor has the successful result.","title":"Handling Exceptions"},{"location":"12-handling-exceptions/notes/#handling-exceptions","text":"Exceptions The exceptions here refers to exceptional cases such as invalid inputs, and not Exception s in languages like Java. Exceptions and control flow Exception s in languages like Java have the problem of interfering with control flow and causes the Exception to propagate.","title":"Handling Exceptions"},{"location":"12-handling-exceptions/notes/#maybe","text":"The usage of Maybe can be used to signal invalid input. Smart constructor -- aliases type Name = String type Age = Int data Person = Person Name Age deriving Show A smart constructor function mkPerson :: Name -> Age -> Maybe Person can be used to allow construction of a datatype only if the inputs satisfy certain constraints. mkPerson :: Name -> Age -> Maybe Person mkPerson name age | name /= \"\" && age >= 0 = Just ( Person name age ) | otherwise = Nothing","title":"Maybe"},{"location":"12-handling-exceptions/notes/#either","text":"In addition to Maybe , where only a success / failure may be indicated, the datatype Either may be used to attach causes of failure. data Either a b = Left a | Right b Indicating failure causes data PersonInvalid = EmptyName | NegativeAge deriving ( Show , Eq ) mkPerson :: Name -> Age -> Either PersonInvalid Person mkPerson name age | name /= \"\" && age >= 0 = Right ( Person name age ) | name == \"\" = Left ( EmptyName ) | otherwise = Left ( NegativeAge ) Notice that the datatype occupying the Left data constructor is the error cause, while the Right data constructor has the successful result.","title":"Either"},{"location":"13-building-projects/notes/","text":"Building Projects \u00b6 Modules \u00b6 The tools used are stack and cabal .","title":"Building Projects"},{"location":"13-building-projects/notes/#building-projects","text":"","title":"Building Projects"},{"location":"13-building-projects/notes/#modules","text":"The tools used are stack and cabal .","title":"Modules"},{"location":"15-monoids-semigroups/notes/","text":"Monoids and Semigroups \u00b6 Algebra \u00b6 An algebra refers to some operations and the sets for which they operate over. In Haskell, algebras are encoded via typeclasses . Monoid \u00b6 A Monoid is a binary associative operation with an identity . Let S S be an set and let \\bullet \\colon S \\times S \\to S \\bullet \\colon S \\times S \\to S , then (S, \\bullet) (S, \\bullet) is a Monoid iff it satisfies two axioms: Associativity . \\forall a, b, c \\in S \\colon (a \\bullet b) \\bullet c \\equiv a \\bullet (b \\bullet c) \\forall a, b, c \\in S \\colon (a \\bullet b) \\bullet c \\equiv a \\bullet (b \\bullet c) Identity . \\exists e \\in S \\colon \\forall a \\in S \\colon e \\bullet a \\equiv a \\bullet e \\equiv a \\exists e \\in S \\colon \\forall a \\in S \\colon e \\bullet a \\equiv a \\bullet e \\equiv a Monoid and Semigroup A monoid is a semigroup with an identity element. In Haskell, a monoid is encoded by the Monoid typeclass. class Monoid m where mempty :: m mappend :: m -> m -> m mconcat :: [ m ] -> m mconcat = foldr mappend mempty Note that the binary operation \\bullet \\bullet corresponds to the mappend operation and identity element corresponds to mempty . Using typeclasses allow us to abstract common patterns out. Monoid defines the infix operator <> to alias mappend . ( <> ) :: Monoid m => m -> m -> m Lists \u00b6 List is a Monoid instance. instance Monoid [ a ] where mempty = [] mappend = ( ++ ) Here appending an empty list [] to any list l does not change l , meaning that the empty list [] is the neutral element. The list concatenation operation ( ++ ) is a binary operation which is in fact associative \u2014 [1, 2] ++ ([3, 4] ++ [5, 6]) == ([1, 2] ++ [3, 4]) ++ [5, 6] . Integers \u00b6 Integer s do not have Monoid instance (also for any other numerical types), because both multiplication and addition have neutral elements and are associative \u2014 but having two operations mean that it is not clear whether to use multiplication or addition, yet each type should only have one unique typeclass instance. The ambiguity is resolved by having wrapper types Sum and Product to wrap numerical values and consequently identify which Monoid instance is desired. Monoid Laws \u00b6 Any Monoid instance must abide by these identities, which are particularily useful for testing. Left identity . mappend mempty x = x -- with infix operator mempty <> x = x Right identity . mappend x mempty = x -- with infix operator x <> mempty = x Associativity . mappend x ( mappend y z ) = mappend ( mappend x y ) z -- with infix operator x <> ( y <> z ) = ( x <> y ) <> z mconcat = foldr mappend mempty -- with infix operator mconcat = foldr ( <> ) mempty Usage \u00b6 Since many types may be more than one sensible Monoid instances, newtype s may be used to differentiate between which particular instance to use. Monoid s should be thought as a way of condensing values (or reducing values into a overall summary representation) for types that do not have straightforward definitions for Monoid . Bool \u00b6 In the case of Bool s, there are two possible Monoid instances, for conjunction \\land \\land and disjunction \\lor \\lor . Here newtype can be used to construct All and Any as newtypes for Bool 's Monoid instance. newtype All = All { getAll :: Bool } newtype Any = Any { getAny :: Bool } All represents the Monoid instance for conjunction ( \\land \\land and) operation, whereas Any represents the Monoid instance for disjunction ( \\lor \\lor or) operation. instance Monoid All where mempty = True mappend = ( && ) instance Monoid Any where mempty = False mappend = ( || ) These definitions are quite intuitive. For conjunction, a \\land \\top = a a \\land \\top = a , whereas for disjunction a \\lor \\bot = a a \\lor \\bot = a . Here, the results of the binary operations only depend on which Bool value a a takes. Maybe \u00b6 Maybe has many possible Monoid instances. First and Last \u00b6 This particular instance is similar to boolean disjunction, but with respect to the leftmost or rightmost success in a series of Maybe s. In the case of Maybe s, a decision must be made if there are multiple successes. First First ( Just 1 ) <> First ( Nothing ) <> First ( Just 3 ) -- => First { getFirst = Just 1 } First ( Nothing ) <> First ( Just 2 ) -- => First { getFirst = Just 2 } Last Last ( Just 1 ) <> Last ( Nothing ) <> Last ( Just 3 ) -- => Last { getLast = Just 3 } Last ( Just 1 ) <> Last ( Nothing ) <> Last ( Nothing ) -- => Last { getLast = Just 1 } Reusing Algebras \u00b6 instance Monoid b => Monoid ( a -> b ) instance ( Monoid a , Monoid b ) => Monoid ( a , b ) instance ( Monoid a , Monoid b , Monoid c ) => Monoid ( a , b , c ) Semigroup \u00b6 A Semigroup is a Monoid without the identity. Given some set S S and a binary associative operation \\bullet \\colon S \\times S \\to S \\bullet \\colon S \\times S \\to S , then (S, \\bullet) (S, \\bullet) is a Semigroup iff it satisfies the associativity axiom: Associativity . \\forall a, b, c \\in S \\colon (a \\bullet b) \\bullet c \\equiv a \\bullet (b \\bullet c) \\forall a, b, c \\in S \\colon (a \\bullet b) \\bullet c \\equiv a \\bullet (b \\bullet c) class Semigroup m where mappend :: m -> m -> m Note that ( <> ) :: Semigroup m => m -> m -> m in the case of Semigroup . Semigroup as superclass of Monoid class Semigroup m => Monoid m where mempty :: m Semigroup Laws \u00b6 The removal of the identity requirement means that only the associativity identity is left. Associativity . mappend x ( mappend y z ) = mappend ( mappend x y ) z -- with infix operator x <> ( y <> z ) = ( x <> y ) <> z NonEmpty \u00b6 A useful datatype which is an instance of Semigroup is the NonEmpty data type which represents a non-empty list. data NonEmpty a = a :| [ a ] deriving ( Eq , Ord , Show ) The infix data constructor :| takes two arguments, an element a and a list [ a ] which may or may not be empty. This guarantees that the data type is always exhibited with at least one element of type a .","title":"Monoids, Semigroups"},{"location":"15-monoids-semigroups/notes/#monoids-and-semigroups","text":"","title":"Monoids and Semigroups"},{"location":"15-monoids-semigroups/notes/#algebra","text":"An algebra refers to some operations and the sets for which they operate over. In Haskell, algebras are encoded via typeclasses .","title":"Algebra"},{"location":"15-monoids-semigroups/notes/#monoid","text":"A Monoid is a binary associative operation with an identity . Let S S be an set and let \\bullet \\colon S \\times S \\to S \\bullet \\colon S \\times S \\to S , then (S, \\bullet) (S, \\bullet) is a Monoid iff it satisfies two axioms: Associativity . \\forall a, b, c \\in S \\colon (a \\bullet b) \\bullet c \\equiv a \\bullet (b \\bullet c) \\forall a, b, c \\in S \\colon (a \\bullet b) \\bullet c \\equiv a \\bullet (b \\bullet c) Identity . \\exists e \\in S \\colon \\forall a \\in S \\colon e \\bullet a \\equiv a \\bullet e \\equiv a \\exists e \\in S \\colon \\forall a \\in S \\colon e \\bullet a \\equiv a \\bullet e \\equiv a Monoid and Semigroup A monoid is a semigroup with an identity element. In Haskell, a monoid is encoded by the Monoid typeclass. class Monoid m where mempty :: m mappend :: m -> m -> m mconcat :: [ m ] -> m mconcat = foldr mappend mempty Note that the binary operation \\bullet \\bullet corresponds to the mappend operation and identity element corresponds to mempty . Using typeclasses allow us to abstract common patterns out. Monoid defines the infix operator <> to alias mappend . ( <> ) :: Monoid m => m -> m -> m","title":"Monoid"},{"location":"15-monoids-semigroups/notes/#lists","text":"List is a Monoid instance. instance Monoid [ a ] where mempty = [] mappend = ( ++ ) Here appending an empty list [] to any list l does not change l , meaning that the empty list [] is the neutral element. The list concatenation operation ( ++ ) is a binary operation which is in fact associative \u2014 [1, 2] ++ ([3, 4] ++ [5, 6]) == ([1, 2] ++ [3, 4]) ++ [5, 6] .","title":"Lists"},{"location":"15-monoids-semigroups/notes/#integers","text":"Integer s do not have Monoid instance (also for any other numerical types), because both multiplication and addition have neutral elements and are associative \u2014 but having two operations mean that it is not clear whether to use multiplication or addition, yet each type should only have one unique typeclass instance. The ambiguity is resolved by having wrapper types Sum and Product to wrap numerical values and consequently identify which Monoid instance is desired.","title":"Integers"},{"location":"15-monoids-semigroups/notes/#monoid-laws","text":"Any Monoid instance must abide by these identities, which are particularily useful for testing. Left identity . mappend mempty x = x -- with infix operator mempty <> x = x Right identity . mappend x mempty = x -- with infix operator x <> mempty = x Associativity . mappend x ( mappend y z ) = mappend ( mappend x y ) z -- with infix operator x <> ( y <> z ) = ( x <> y ) <> z mconcat = foldr mappend mempty -- with infix operator mconcat = foldr ( <> ) mempty","title":"Monoid Laws"},{"location":"15-monoids-semigroups/notes/#usage","text":"Since many types may be more than one sensible Monoid instances, newtype s may be used to differentiate between which particular instance to use. Monoid s should be thought as a way of condensing values (or reducing values into a overall summary representation) for types that do not have straightforward definitions for Monoid .","title":"Usage"},{"location":"15-monoids-semigroups/notes/#bool","text":"In the case of Bool s, there are two possible Monoid instances, for conjunction \\land \\land and disjunction \\lor \\lor . Here newtype can be used to construct All and Any as newtypes for Bool 's Monoid instance. newtype All = All { getAll :: Bool } newtype Any = Any { getAny :: Bool } All represents the Monoid instance for conjunction ( \\land \\land and) operation, whereas Any represents the Monoid instance for disjunction ( \\lor \\lor or) operation. instance Monoid All where mempty = True mappend = ( && ) instance Monoid Any where mempty = False mappend = ( || ) These definitions are quite intuitive. For conjunction, a \\land \\top = a a \\land \\top = a , whereas for disjunction a \\lor \\bot = a a \\lor \\bot = a . Here, the results of the binary operations only depend on which Bool value a a takes.","title":"Bool"},{"location":"15-monoids-semigroups/notes/#maybe","text":"Maybe has many possible Monoid instances.","title":"Maybe"},{"location":"15-monoids-semigroups/notes/#first-and-last","text":"This particular instance is similar to boolean disjunction, but with respect to the leftmost or rightmost success in a series of Maybe s. In the case of Maybe s, a decision must be made if there are multiple successes. First First ( Just 1 ) <> First ( Nothing ) <> First ( Just 3 ) -- => First { getFirst = Just 1 } First ( Nothing ) <> First ( Just 2 ) -- => First { getFirst = Just 2 } Last Last ( Just 1 ) <> Last ( Nothing ) <> Last ( Just 3 ) -- => Last { getLast = Just 3 } Last ( Just 1 ) <> Last ( Nothing ) <> Last ( Nothing ) -- => Last { getLast = Just 1 }","title":"First and Last"},{"location":"15-monoids-semigroups/notes/#reusing-algebras","text":"instance Monoid b => Monoid ( a -> b ) instance ( Monoid a , Monoid b ) => Monoid ( a , b ) instance ( Monoid a , Monoid b , Monoid c ) => Monoid ( a , b , c )","title":"Reusing Algebras"},{"location":"15-monoids-semigroups/notes/#semigroup","text":"A Semigroup is a Monoid without the identity. Given some set S S and a binary associative operation \\bullet \\colon S \\times S \\to S \\bullet \\colon S \\times S \\to S , then (S, \\bullet) (S, \\bullet) is a Semigroup iff it satisfies the associativity axiom: Associativity . \\forall a, b, c \\in S \\colon (a \\bullet b) \\bullet c \\equiv a \\bullet (b \\bullet c) \\forall a, b, c \\in S \\colon (a \\bullet b) \\bullet c \\equiv a \\bullet (b \\bullet c) class Semigroup m where mappend :: m -> m -> m Note that ( <> ) :: Semigroup m => m -> m -> m in the case of Semigroup . Semigroup as superclass of Monoid class Semigroup m => Monoid m where mempty :: m","title":"Semigroup"},{"location":"15-monoids-semigroups/notes/#semigroup-laws","text":"The removal of the identity requirement means that only the associativity identity is left. Associativity . mappend x ( mappend y z ) = mappend ( mappend x y ) z -- with infix operator x <> ( y <> z ) = ( x <> y ) <> z","title":"Semigroup Laws"},{"location":"15-monoids-semigroups/notes/#nonempty","text":"A useful datatype which is an instance of Semigroup is the NonEmpty data type which represents a non-empty list. data NonEmpty a = a :| [ a ] deriving ( Eq , Ord , Show ) The infix data constructor :| takes two arguments, an element a and a list [ a ] which may or may not be empty. This guarantees that the data type is always exhibited with at least one element of type a .","title":"NonEmpty"},{"location":"16-functors/notes/","text":"Functors \u00b6 The Functor typeclass is about abstracting mapping over structures. Negation Logical negation ( \\neg \\neg ) can be considered a Functor since when \\neg \\neg is applied to some input sentence A A , it outputs \\neg A \\neg A ; the concept of negation is lifted over the entire sentence and does not change the internal structure \u2014 here, the terms within the sentence A A remains unchanged and the negation operator is applied to the entire sentence. Basics \u00b6 A Functor is an abstraction for applying a function to values within some structure without altering the structure itself. class Functor f where fmap :: ( a -> b ) -> f a -> f b fmap is aliased with the infix operator <$> . <$> :: Functor f => ( a -> b ) -> f a -> f b Explicit kind signatures It is possible to give explicit type signatures, for example: class Functor ( f :: * -> * ) where fmap :: ( a -> b ) -> f a -> f b Functor Laws \u00b6 Identity fmap id == id Composition fmap ( f . g ) == fmap f . fmap g Structure Preservation \u00b6 The two identities guarantee that Functor s shall be structure-preserving. In the sigature of fmap :: Functor f => ( a -> b ) -> f a -> f b , since the input structure f is identical to the output structure f , then it can be deduced that fmap does not alter the underlying structure. Uniqueness to Datatype \u00b6 Functor instances will be unique for its datatype because of the parametricity in the type arguments, requiring the structure f in\\ Functor f to have precisely the kind f :: * -> * .","title":"Functors"},{"location":"16-functors/notes/#functors","text":"The Functor typeclass is about abstracting mapping over structures. Negation Logical negation ( \\neg \\neg ) can be considered a Functor since when \\neg \\neg is applied to some input sentence A A , it outputs \\neg A \\neg A ; the concept of negation is lifted over the entire sentence and does not change the internal structure \u2014 here, the terms within the sentence A A remains unchanged and the negation operator is applied to the entire sentence.","title":"Functors"},{"location":"16-functors/notes/#basics","text":"A Functor is an abstraction for applying a function to values within some structure without altering the structure itself. class Functor f where fmap :: ( a -> b ) -> f a -> f b fmap is aliased with the infix operator <$> . <$> :: Functor f => ( a -> b ) -> f a -> f b Explicit kind signatures It is possible to give explicit type signatures, for example: class Functor ( f :: * -> * ) where fmap :: ( a -> b ) -> f a -> f b","title":"Basics"},{"location":"16-functors/notes/#functor-laws","text":"Identity fmap id == id Composition fmap ( f . g ) == fmap f . fmap g","title":"Functor Laws"},{"location":"16-functors/notes/#structure-preservation","text":"The two identities guarantee that Functor s shall be structure-preserving. In the sigature of fmap :: Functor f => ( a -> b ) -> f a -> f b , since the input structure f is identical to the output structure f , then it can be deduced that fmap does not alter the underlying structure.","title":"Structure Preservation"},{"location":"16-functors/notes/#uniqueness-to-datatype","text":"Functor instances will be unique for its datatype because of the parametricity in the type arguments, requiring the structure f in\\ Functor f to have precisely the kind f :: * -> * .","title":"Uniqueness to Datatype"},{"location":"17-applicatives/notes/","text":"Applicatives \u00b6 Applicative s are monoidal functors (i.e. the additive combination of Monoid s and Functor s). For Applicative s, the function and its target value both have structures which are expected to be altered, and combined. class Functor f => Applicative f where pure :: a -> f a ( <*> ) :: f ( a -> b ) -> f a -> f b It is hence implied that any type which is an instance of Applicative is also consequently an instance of Functor . The pure operation lifts some value a into a minimal structure f , i.e. a into an structural identity. Similarity between fmap and <*> -- fmap <$> :: Functor f => ( a -> b ) -> f a -> f b -- apply <*> :: Applicative f => f ( a -> b ) -> f a -> f b Notice that <*> 's function ( a -> b ) is boxed within a functorial structure f . Some convenience functions are also provided in Control . Applicative . liftA :: Applicative f => ( a -> b ) -> f a -> f b liftA2 :: Applicative f => ( a -> b -> c ) -> f a -> f b -> f c liftA3 :: Applicative f => ( a -> b -> c -> d ) -> f a -> f b -> f c -> f d Notice that liftA is almost identical to fmap except that the typeclass constraint on f is Applicative instead of Functor . Functors and Applicatives \u00b6 A Functor can be defined in terms of an Applicative because Applicative has all the operators of an Functor and more. fmap f x = pure f <*> x -- or as prefix fmap f x = ( <*> ) ( pure f ) x Applicative Functors and Monoidal Functors \u00b6 ( $ ) :: ( a -> b ) -> a -> b ( <$> ) :: ( a -> b ) -> f a -> f b ( <*> ) :: f ( a -> b ) -> f a -> f b Notice that from function application ( $ ) to fmap ( <$> ) we wrapped the input and output value with some structure f \u2014 this is the added functionality from Functor regarding structure preservance. From fmap ( <$> ) we also wrap the mapping function in some structure bit, having two piece of structure f in the argument to apply <*> . To combine these two bits of structure f and end up with one single bit of structure f in the output, we need the combining concept from Monoid . If the structure bit and function bit is split in the signature of apply <*> , it is easier to see the functionality provided by Functor and Monoid respectively. ( <*> ) :: f ( a -> b ) -> f a -> f b -- functor ( a -> b ) -> a -> b -- monoid f -> f -> f We can then use Monoid 's mappend for combining the two input structure bit, and normal function application ( $ ) for the function and value bit. mappend :: f -> f -> f ( $ ) :: ( a -> b ) -> a -> b ( <*> ) :: f ( a -> b ) -> f a -> f b Applicative Laws \u00b6 Identity pure id <*> v = v Composition pure ( . ) <*> u <*> v <*> w = u <*> ( v <*> w ) Homomorphism (structure-preserving map) pure f <*> pure x = pure ( f x ) Interchange u <*> pure y = pure ( $ y ) <*> u","title":"Applicatives"},{"location":"17-applicatives/notes/#applicatives","text":"Applicative s are monoidal functors (i.e. the additive combination of Monoid s and Functor s). For Applicative s, the function and its target value both have structures which are expected to be altered, and combined. class Functor f => Applicative f where pure :: a -> f a ( <*> ) :: f ( a -> b ) -> f a -> f b It is hence implied that any type which is an instance of Applicative is also consequently an instance of Functor . The pure operation lifts some value a into a minimal structure f , i.e. a into an structural identity. Similarity between fmap and <*> -- fmap <$> :: Functor f => ( a -> b ) -> f a -> f b -- apply <*> :: Applicative f => f ( a -> b ) -> f a -> f b Notice that <*> 's function ( a -> b ) is boxed within a functorial structure f . Some convenience functions are also provided in Control . Applicative . liftA :: Applicative f => ( a -> b ) -> f a -> f b liftA2 :: Applicative f => ( a -> b -> c ) -> f a -> f b -> f c liftA3 :: Applicative f => ( a -> b -> c -> d ) -> f a -> f b -> f c -> f d Notice that liftA is almost identical to fmap except that the typeclass constraint on f is Applicative instead of Functor .","title":"Applicatives"},{"location":"17-applicatives/notes/#functors-and-applicatives","text":"A Functor can be defined in terms of an Applicative because Applicative has all the operators of an Functor and more. fmap f x = pure f <*> x -- or as prefix fmap f x = ( <*> ) ( pure f ) x","title":"Functors and Applicatives"},{"location":"17-applicatives/notes/#applicative-functors-and-monoidal-functors","text":"( $ ) :: ( a -> b ) -> a -> b ( <$> ) :: ( a -> b ) -> f a -> f b ( <*> ) :: f ( a -> b ) -> f a -> f b Notice that from function application ( $ ) to fmap ( <$> ) we wrapped the input and output value with some structure f \u2014 this is the added functionality from Functor regarding structure preservance. From fmap ( <$> ) we also wrap the mapping function in some structure bit, having two piece of structure f in the argument to apply <*> . To combine these two bits of structure f and end up with one single bit of structure f in the output, we need the combining concept from Monoid . If the structure bit and function bit is split in the signature of apply <*> , it is easier to see the functionality provided by Functor and Monoid respectively. ( <*> ) :: f ( a -> b ) -> f a -> f b -- functor ( a -> b ) -> a -> b -- monoid f -> f -> f We can then use Monoid 's mappend for combining the two input structure bit, and normal function application ( $ ) for the function and value bit. mappend :: f -> f -> f ( $ ) :: ( a -> b ) -> a -> b ( <*> ) :: f ( a -> b ) -> f a -> f b","title":"Applicative Functors and Monoidal Functors"},{"location":"17-applicatives/notes/#applicative-laws","text":"Identity pure id <*> v = v Composition pure ( . ) <*> u <*> v <*> w = u <*> ( v <*> w ) Homomorphism (structure-preserving map) pure f <*> pure x = pure ( f x ) Interchange u <*> pure y = pure ( $ y ) <*> u","title":"Applicative Laws"},{"location":"18-monads/notes/","text":"Monads \u00b6 Monad s are applicative functors with additional features. class Applicative m => Monad m where ( >>= ) :: m a -> ( a -> m b ) -> m b ( >> ) :: m a -> m b -> m b return :: a -> m a return does the same thing as Applicative 's pure , which is to wrap a value into some structure m (which happens to be a Monad instead of just Applicative ). The sequencing operator ( >> ) sequences two actions m a and m b and discards any results from m a . The bind operator ( >>= ) (often used via the do syntax) takes some wrapped value m a and a mapping function ( a -> m b ) and feeds the underlying value a from m a into the function, which in turn yields m b . But Monad s can cause structures to be wrapped inside structures. To flatten such thick layers, the join operation is defined for Monad s which is able to flatten two Monad layers into one. join :: Monad m => m ( m a ) -> m a Applicative m Since Monad is stronger than Applicative , which is in turn stronger than Functor , both Applicative and Functor can be defined via Monad since they are both less powerful. fmap f xs = xs >>= return . f Misconcepts regarding Monad Monad s are pure . Monad s are not imperative, since commutative Monad s do not need to order actions (useful property for concurrency!). Monad s are not values. Monad s are not about strict vs lazy. Lifting \u00b6 Monad s also have corresponding lift functions, just like those of Applicative s. liftM :: Monad m => ( a1 -> r ) -> m a1 -> m r liftM2 :: Monad m => ( a1 -> a2 -> r ) -> m a1 -> m a2 -> m r Monad and Do Syntax \u00b6 ( *> ) :: Applicative f => f a -> f b -> f b ( >> ) :: Monad m => m a -> m b -> m b The operators ( *> ) and ( >> ) are both sequencing operators with different typeclass constraint on the structure. The join operation allows us to merge two effects into a single effect. Monad Laws \u00b6 Left Identity . return x >>= f = f x 2. Right Identity . m >>= return = m Associativity . ( m >>= f ) >>= g = m >>= ( \\ x -> f x >>= g ) Kleisli Composition (\u00e0 la Fish ) \u00b6 ( >=> ) :: Monad m => ( a -> m b ) -> ( b -> m c ) -> a -> m c Notice the similarity between the fish operator ( >=> ) and flipped regular function composition operator flip ( . ) . flip ( . ) :: ( a -> b ) -> ( b -> c ) -> a -> c","title":"Monads"},{"location":"18-monads/notes/#monads","text":"Monad s are applicative functors with additional features. class Applicative m => Monad m where ( >>= ) :: m a -> ( a -> m b ) -> m b ( >> ) :: m a -> m b -> m b return :: a -> m a return does the same thing as Applicative 's pure , which is to wrap a value into some structure m (which happens to be a Monad instead of just Applicative ). The sequencing operator ( >> ) sequences two actions m a and m b and discards any results from m a . The bind operator ( >>= ) (often used via the do syntax) takes some wrapped value m a and a mapping function ( a -> m b ) and feeds the underlying value a from m a into the function, which in turn yields m b . But Monad s can cause structures to be wrapped inside structures. To flatten such thick layers, the join operation is defined for Monad s which is able to flatten two Monad layers into one. join :: Monad m => m ( m a ) -> m a Applicative m Since Monad is stronger than Applicative , which is in turn stronger than Functor , both Applicative and Functor can be defined via Monad since they are both less powerful. fmap f xs = xs >>= return . f Misconcepts regarding Monad Monad s are pure . Monad s are not imperative, since commutative Monad s do not need to order actions (useful property for concurrency!). Monad s are not values. Monad s are not about strict vs lazy.","title":"Monads"},{"location":"18-monads/notes/#lifting","text":"Monad s also have corresponding lift functions, just like those of Applicative s. liftM :: Monad m => ( a1 -> r ) -> m a1 -> m r liftM2 :: Monad m => ( a1 -> a2 -> r ) -> m a1 -> m a2 -> m r","title":"Lifting"},{"location":"18-monads/notes/#monad-and-do-syntax","text":"( *> ) :: Applicative f => f a -> f b -> f b ( >> ) :: Monad m => m a -> m b -> m b The operators ( *> ) and ( >> ) are both sequencing operators with different typeclass constraint on the structure. The join operation allows us to merge two effects into a single effect.","title":"Monad and Do Syntax"},{"location":"18-monads/notes/#monad-laws","text":"Left Identity . return x >>= f = f x 2. Right Identity . m >>= return = m Associativity . ( m >>= f ) >>= g = m >>= ( \\ x -> f x >>= g )","title":"Monad Laws"},{"location":"18-monads/notes/#kleisli-composition-a-la-fish","text":"( >=> ) :: Monad m => ( a -> m b ) -> ( b -> m c ) -> a -> m c Notice the similarity between the fish operator ( >=> ) and flipped regular function composition operator flip ( . ) . flip ( . ) :: ( a -> b ) -> ( b -> c ) -> a -> c","title":"Kleisli Composition (\u00e0 la Fish )"},{"location":"2-haskell-basics/notes/","text":"Haskell Basics \u00b6 Prelude \u00b6 The Prelude is a collection of standard library functions and typeclasses. The Glasgow Haskell Compiler (GHC) has a default Prelude , but one is also able to supply a custom Prelude if necessary. Type Signatures \u00b6 The double colon operator :: denotes that some identifier \" has the type \". That is, id :: TypeName denotes that some identifier id has the type TypeName . Expressions \u00b6 Haskell expressions may be: Values; Combination of values (e.g. arithmetic expressions); and/or Functions applied to values. Declarations \u00b6 Haskell declarations are top-level bindings which assign names to expressions, allowing programmers to refer to such expressions by names. Normal Form \u00b6 Expressions are in normal form if no further reduction steps may be performed (i.e. in irreducible form ). Normal form The expression 1 + 1 is not in normal form since it can be reduced to 2 , which is in normal form. This is done by applying the addition operator ( + ) :: Int -> Int -> Int to two arguments, two 1 s. Redexes Reducible expressions are also called redexes . Functions \u00b6 Since Haskell functions follow those of lambda calculus, each function takes only one argument. With currying \u2014 by applying a series of nested functions with each taking one argument, the innermost expression can obtain the values of multiple arguments. Functions allow programmers to name arguments and the purposes of expressions. This facilitates code reuse and documentation. Function Definition \u00b6 A function definition consists of: Name of function; Formal parameters; Assignment operator = ; Body expression. Example function definition In the function definition double x = x * 2 -- [1] [2] [3] [4] [1] is the function's name; [2] is the single parameter's name; [3] is the definition operator expressing equality; [4] is the body expression. Evaluation \u00b6 When some expression is evaluated , its terms are reduced until the simplest irreducible form, i.e. normal form . Haskell uses lazy evalution which avoids evaluation of terms unless it is inevitable. Haskell does not evaluate everything to normal form by default: It evaluates expressions to weak head normal form (WHNF) by default. Weak head normal form For some expression like ( \\ x -> ( 1 , 1 + x )) 1 Haskell only evaluates to the next intermediate form ( 1 , 1 + 1 ) Unless the final result ( 1 , 2 ) must be evaluated. Infix Operators \u00b6 By default, functions in Haskell are in prefix syntax. Operators are functions which can be used in the infix style. Infix operator The arithmetic addition operator ( + ) is an infix operator. It can also be used as a prefix function ( + ) 1 2 Which is identical to 1 + 2 Some functions like div may be used infix by using backticks: 10 ` div ` 2 == div 10 2 Associativity and Precedence \u00b6 Precendence information on operators may be obtained from GHCi with the :info command. GHCi returns: Type information; Infix or prefix; If infix, then its precedence and associativity; : info ( * ) For the multiplication operator ( * ) GHCi returns infixl 7 * infixl means that the operator ( * ) is an infix operator and is left associative. 7 is ( * ) 's precendece level (between 0-9). * is the operator's name, i.e. multiplication. Associativity Left Associativity For some left associative operator like ( * ) , an expression such as 1 * 3 * 5 is equivalent to (1 * 3) * 5 with parentheses denoting evaluation order, from left to right. Right Associativity For some right associative oerator like ( ^ ) , an expression such as 1 ^ 3 ^ 5 is equivalent to 1 ^ (3 ^ 5) , from right to left. Value Declaration \u00b6 In a Haskell source file {filename}.hs , -- file: arith.hs module Arith where addOne x = x + 1 fileName.hs declares a module Arith . Module name is capitalized and named with PascalCase . Function, variable and parameter names use camelCase . Arithmetic Functions \u00b6 Operator Name Usage ( + ) Plus Addition ( - ) Minus Subtraction ( * ) Asterisk Multiplication ( / ) Slash Fractional division div Divide Integral division, round down mod Modulo Modulo division quot Quotient Integral division, round towards zero rem Remainder Remainder after division Negative Numbers \u00b6 Because ( - ) is an operator, negative numbers may need parentheses to disambiguate. Negative Integer 100 + ( - 9 ) Dollar ($) Operator \u00b6 The ( $ ) operator has the signature ( $ ) :: ( a -> b ) -> a -> b f $ a = f a GHCi gives infixr 0 $ upon using the : info command. It is right associative, and of the lowest possible precedence. This operator helps to reduce the number of parentheses: ( 2 ^ ) ( 2 + 2 ) == ( 2 ^ ) $ 2 + 2 The binary arithmetic operators can be partially applied (e.g. (2^) ), and this is called sectioning . Let and Where \u00b6 The let keyword is part of a let binding expression, while the where keyword is part of a where clause declaration. Both let and where allows extracting parts of an expression and giving them names. Where example printHello name = print greeting where greeting = \"Hello \" ++ name ++ \"!\" Let example printHello name = let greeting = \"Hello \" ++ name ++ \"!\" in print greeting","title":"Haskell Basics"},{"location":"2-haskell-basics/notes/#haskell-basics","text":"","title":"Haskell Basics"},{"location":"2-haskell-basics/notes/#prelude","text":"The Prelude is a collection of standard library functions and typeclasses. The Glasgow Haskell Compiler (GHC) has a default Prelude , but one is also able to supply a custom Prelude if necessary.","title":"Prelude"},{"location":"2-haskell-basics/notes/#type-signatures","text":"The double colon operator :: denotes that some identifier \" has the type \". That is, id :: TypeName denotes that some identifier id has the type TypeName .","title":"Type Signatures"},{"location":"2-haskell-basics/notes/#expressions","text":"Haskell expressions may be: Values; Combination of values (e.g. arithmetic expressions); and/or Functions applied to values.","title":"Expressions"},{"location":"2-haskell-basics/notes/#declarations","text":"Haskell declarations are top-level bindings which assign names to expressions, allowing programmers to refer to such expressions by names.","title":"Declarations"},{"location":"2-haskell-basics/notes/#normal-form","text":"Expressions are in normal form if no further reduction steps may be performed (i.e. in irreducible form ). Normal form The expression 1 + 1 is not in normal form since it can be reduced to 2 , which is in normal form. This is done by applying the addition operator ( + ) :: Int -> Int -> Int to two arguments, two 1 s. Redexes Reducible expressions are also called redexes .","title":"Normal Form"},{"location":"2-haskell-basics/notes/#functions","text":"Since Haskell functions follow those of lambda calculus, each function takes only one argument. With currying \u2014 by applying a series of nested functions with each taking one argument, the innermost expression can obtain the values of multiple arguments. Functions allow programmers to name arguments and the purposes of expressions. This facilitates code reuse and documentation.","title":"Functions"},{"location":"2-haskell-basics/notes/#function-definition","text":"A function definition consists of: Name of function; Formal parameters; Assignment operator = ; Body expression. Example function definition In the function definition double x = x * 2 -- [1] [2] [3] [4] [1] is the function's name; [2] is the single parameter's name; [3] is the definition operator expressing equality; [4] is the body expression.","title":"Function Definition"},{"location":"2-haskell-basics/notes/#evaluation","text":"When some expression is evaluated , its terms are reduced until the simplest irreducible form, i.e. normal form . Haskell uses lazy evalution which avoids evaluation of terms unless it is inevitable. Haskell does not evaluate everything to normal form by default: It evaluates expressions to weak head normal form (WHNF) by default. Weak head normal form For some expression like ( \\ x -> ( 1 , 1 + x )) 1 Haskell only evaluates to the next intermediate form ( 1 , 1 + 1 ) Unless the final result ( 1 , 2 ) must be evaluated.","title":"Evaluation"},{"location":"2-haskell-basics/notes/#infix-operators","text":"By default, functions in Haskell are in prefix syntax. Operators are functions which can be used in the infix style. Infix operator The arithmetic addition operator ( + ) is an infix operator. It can also be used as a prefix function ( + ) 1 2 Which is identical to 1 + 2 Some functions like div may be used infix by using backticks: 10 ` div ` 2 == div 10 2","title":"Infix Operators"},{"location":"2-haskell-basics/notes/#associativity-and-precedence","text":"Precendence information on operators may be obtained from GHCi with the :info command. GHCi returns: Type information; Infix or prefix; If infix, then its precedence and associativity; : info ( * ) For the multiplication operator ( * ) GHCi returns infixl 7 * infixl means that the operator ( * ) is an infix operator and is left associative. 7 is ( * ) 's precendece level (between 0-9). * is the operator's name, i.e. multiplication. Associativity Left Associativity For some left associative operator like ( * ) , an expression such as 1 * 3 * 5 is equivalent to (1 * 3) * 5 with parentheses denoting evaluation order, from left to right. Right Associativity For some right associative oerator like ( ^ ) , an expression such as 1 ^ 3 ^ 5 is equivalent to 1 ^ (3 ^ 5) , from right to left.","title":"Associativity and Precedence"},{"location":"2-haskell-basics/notes/#value-declaration","text":"In a Haskell source file {filename}.hs , -- file: arith.hs module Arith where addOne x = x + 1 fileName.hs declares a module Arith . Module name is capitalized and named with PascalCase . Function, variable and parameter names use camelCase .","title":"Value Declaration"},{"location":"2-haskell-basics/notes/#arithmetic-functions","text":"Operator Name Usage ( + ) Plus Addition ( - ) Minus Subtraction ( * ) Asterisk Multiplication ( / ) Slash Fractional division div Divide Integral division, round down mod Modulo Modulo division quot Quotient Integral division, round towards zero rem Remainder Remainder after division","title":"Arithmetic Functions"},{"location":"2-haskell-basics/notes/#negative-numbers","text":"Because ( - ) is an operator, negative numbers may need parentheses to disambiguate. Negative Integer 100 + ( - 9 )","title":"Negative Numbers"},{"location":"2-haskell-basics/notes/#dollar-operator","text":"The ( $ ) operator has the signature ( $ ) :: ( a -> b ) -> a -> b f $ a = f a GHCi gives infixr 0 $ upon using the : info command. It is right associative, and of the lowest possible precedence. This operator helps to reduce the number of parentheses: ( 2 ^ ) ( 2 + 2 ) == ( 2 ^ ) $ 2 + 2 The binary arithmetic operators can be partially applied (e.g. (2^) ), and this is called sectioning .","title":"Dollar ($) Operator"},{"location":"2-haskell-basics/notes/#let-and-where","text":"The let keyword is part of a let binding expression, while the where keyword is part of a where clause declaration. Both let and where allows extracting parts of an expression and giving them names. Where example printHello name = print greeting where greeting = \"Hello \" ++ name ++ \"!\" Let example printHello name = let greeting = \"Hello \" ++ name ++ \"!\" in print greeting","title":"Let and Where"},{"location":"20-foldable/notes/","text":"Foldable \u00b6 The Foldable typeclass describes a class of datatypes which can be folded into a summary value . -- A MINIMAL annotaion requires that any Foldable typeclass instance must at -- lease specify either foldMap or foldr. class Foldable t where {-# MINIMAL foldMap | foldr #-} fold :: Monoid m => t m -> m foldMap :: Monoid m => ( a -> m ) -> t a -> m Here fold allows values of type m within some structure t to be combined via their Monoid instances. The foldMap operation first maps elements of type a to some type m which is an instance of Monoid in order to get the value-combining capability, and then combines the values into a summary value via the Monoid instance. With explicit kind signatures class Foldable ( t :: * -> * ) where {-# MINIMAL foldMap | foldr #-} fold fold ( + ) $ map Sum [ 1 .. 5 ] Notice the map Sum required to lift [1..5] into their Sum Monoid instances. foldMap foldMap Product [ 1 .. 5 ] Here the function argument of foldMap is required to map each elment of [ 1 .. 5 ] into some Monoid instance, in this case Product . Derived Operations \u00b6 To List \u00b6 toList :: Foldable t => t a -> [ a ] Length \u00b6 length :: Foldable t => t a -> Int Element Of \u00b6 elem :: ( Eq a , Foldable t ) => a -> t a -> Bool Largest and Least Element \u00b6 maximum :: Ord a => t a -> a minimum :: Ord a => t a -> a Sum and Product \u00b6 sum :: ( Foldable t , Num a ) => t a -> a product :: ( Foldable t , Num a ) => t a -> a Null \u00b6 Is the Foldable structure empty? null :: Foldable t => t a -> Bool","title":"Foldable"},{"location":"20-foldable/notes/#foldable","text":"The Foldable typeclass describes a class of datatypes which can be folded into a summary value . -- A MINIMAL annotaion requires that any Foldable typeclass instance must at -- lease specify either foldMap or foldr. class Foldable t where {-# MINIMAL foldMap | foldr #-} fold :: Monoid m => t m -> m foldMap :: Monoid m => ( a -> m ) -> t a -> m Here fold allows values of type m within some structure t to be combined via their Monoid instances. The foldMap operation first maps elements of type a to some type m which is an instance of Monoid in order to get the value-combining capability, and then combines the values into a summary value via the Monoid instance. With explicit kind signatures class Foldable ( t :: * -> * ) where {-# MINIMAL foldMap | foldr #-} fold fold ( + ) $ map Sum [ 1 .. 5 ] Notice the map Sum required to lift [1..5] into their Sum Monoid instances. foldMap foldMap Product [ 1 .. 5 ] Here the function argument of foldMap is required to map each elment of [ 1 .. 5 ] into some Monoid instance, in this case Product .","title":"Foldable"},{"location":"20-foldable/notes/#derived-operations","text":"","title":"Derived Operations"},{"location":"20-foldable/notes/#to-list","text":"toList :: Foldable t => t a -> [ a ]","title":"To List"},{"location":"20-foldable/notes/#length","text":"length :: Foldable t => t a -> Int","title":"Length"},{"location":"20-foldable/notes/#element-of","text":"elem :: ( Eq a , Foldable t ) => a -> t a -> Bool","title":"Element Of"},{"location":"20-foldable/notes/#largest-and-least-element","text":"maximum :: Ord a => t a -> a minimum :: Ord a => t a -> a","title":"Largest and Least Element"},{"location":"20-foldable/notes/#sum-and-product","text":"sum :: ( Foldable t , Num a ) => t a -> a product :: ( Foldable t , Num a ) => t a -> a","title":"Sum and Product"},{"location":"20-foldable/notes/#null","text":"Is the Foldable structure empty? null :: Foldable t => t a -> Bool","title":"Null"},{"location":"21-traversable/notes/","text":"Traversable \u00b6 The Traversable typeclass defined in Data . Traversable is given as class ( Functor t , Foldable t ) => Traversable t where {-# MINIMAL traverse | sequenceA #-} traverse :: Applicative f => ( a -> f b ) -> t a -> f ( t b ) traverse f = sequenceA . fmap f sequenceA :: Applicative f => t ( f a ) -> f ( t a ) sequenceA = traverse id The traverse operation: Maps elements of some structure to actions; Evaluates such actions from left to right; Collects the result. SequenceA \u00b6 The sequenceA operation flips the two layers of structures/contexts and does not allow any additional functions to be applied to values contained inside. sequenceA fmap Just [ 1 , 2 , 3 ] -- ==> [Just 1, Just 2, Just 3] sequenceA $ fmap Just [ 1 , 2 , 3 ] -- ==> Just [1, 2, 3] sequenceA [ Just 1 , Just 2 , Just 3 ] -- ==> Just [1, 2, 3] Traverse \u00b6 traverse :: ( Applicative f , Traversable t ) => ( a -> f b ) -> t a -> f ( t b ) Which is similar to fmap and ( =<< ) (flipped bind): fmap :: Functor f => ( a -> b ) -> f a -> f b ( =<< ) :: Monad m => ( a -> m b ) -> m a -> m b traverse :: ( Applicative f , Traversable t ) => ( a -> f b ) -> t a -> f ( t b ) The same beneath-structure value-mapping still occurs like fmap , like flipped bind, traverse also generates more structure. Notice that different to ( =<< ) , traverse can have different structure type in the result compared to the structure that was lifted for the function to apply to, and eventually will flip the two structures f and t around. MapM and Traverse, Sequence and SequenceA \u00b6 There are legacy operations mapM and sequence which are defined in GHC 7.10 and before which are less general versions of traverse and sequenceA respectively. mapM :: Monad m => ( a -> m b ) -> [] a -> m ( [] b ) traverse :: ( Applicative f , Traversable t ) => ( a -> f b ) -> t a -> f ( t b ) Notice that traverse is a generalization of mapM to other Traversable structures not just limited to lists [] , and also loosening the typeclass constraint from Monad to only requring an Applicative . sequence :: Monad m => [] ( m a ) -> m ( [] a ) sequenceA :: ( Applicative f , Traversable t ) => t ( f a ) -> f ( t a ) Notice that sequenceA is a generalization of sequence in both generalizing to Traversable structures not only restricted to lists [] , but also loosening the typeclass constraint from Monad to Applicative . Use Case \u00b6 Traversable is useful for flipping two type constructors (optionally also mapping in the process). Traversable It may be case that some function returns a list of Maybe s, i.e. [ Maybe a ] , but we may want Maybe [ a ] instead. Semantically, it may convey different meaning: a list of possible values is different from a possible list of values. Traversable Laws \u00b6 traverse \u00b6 Naturality . t . traverse f = traverse ( t . f ) Identity . traverse Identity = Identity Composition . traverse ( Compose . fmap g . f ) = Compose . fmap ( traverse g ) . traverse f sequenceA \u00b6 The sequenceA must satisfy: Naturality . t . sequenceA = sequenceA . fmap t Identity . sequenceA . fmap Identity = Identity Composition . sequenceA . fmap Compose = Compose . fmap sequenceA . sequenceA","title":"Traversable"},{"location":"21-traversable/notes/#traversable","text":"The Traversable typeclass defined in Data . Traversable is given as class ( Functor t , Foldable t ) => Traversable t where {-# MINIMAL traverse | sequenceA #-} traverse :: Applicative f => ( a -> f b ) -> t a -> f ( t b ) traverse f = sequenceA . fmap f sequenceA :: Applicative f => t ( f a ) -> f ( t a ) sequenceA = traverse id The traverse operation: Maps elements of some structure to actions; Evaluates such actions from left to right; Collects the result.","title":"Traversable"},{"location":"21-traversable/notes/#sequencea","text":"The sequenceA operation flips the two layers of structures/contexts and does not allow any additional functions to be applied to values contained inside. sequenceA fmap Just [ 1 , 2 , 3 ] -- ==> [Just 1, Just 2, Just 3] sequenceA $ fmap Just [ 1 , 2 , 3 ] -- ==> Just [1, 2, 3] sequenceA [ Just 1 , Just 2 , Just 3 ] -- ==> Just [1, 2, 3]","title":"SequenceA"},{"location":"21-traversable/notes/#traverse","text":"traverse :: ( Applicative f , Traversable t ) => ( a -> f b ) -> t a -> f ( t b ) Which is similar to fmap and ( =<< ) (flipped bind): fmap :: Functor f => ( a -> b ) -> f a -> f b ( =<< ) :: Monad m => ( a -> m b ) -> m a -> m b traverse :: ( Applicative f , Traversable t ) => ( a -> f b ) -> t a -> f ( t b ) The same beneath-structure value-mapping still occurs like fmap , like flipped bind, traverse also generates more structure. Notice that different to ( =<< ) , traverse can have different structure type in the result compared to the structure that was lifted for the function to apply to, and eventually will flip the two structures f and t around.","title":"Traverse"},{"location":"21-traversable/notes/#mapm-and-traverse-sequence-and-sequencea","text":"There are legacy operations mapM and sequence which are defined in GHC 7.10 and before which are less general versions of traverse and sequenceA respectively. mapM :: Monad m => ( a -> m b ) -> [] a -> m ( [] b ) traverse :: ( Applicative f , Traversable t ) => ( a -> f b ) -> t a -> f ( t b ) Notice that traverse is a generalization of mapM to other Traversable structures not just limited to lists [] , and also loosening the typeclass constraint from Monad to only requring an Applicative . sequence :: Monad m => [] ( m a ) -> m ( [] a ) sequenceA :: ( Applicative f , Traversable t ) => t ( f a ) -> f ( t a ) Notice that sequenceA is a generalization of sequence in both generalizing to Traversable structures not only restricted to lists [] , but also loosening the typeclass constraint from Monad to Applicative .","title":"MapM and Traverse, Sequence and SequenceA"},{"location":"21-traversable/notes/#use-case","text":"Traversable is useful for flipping two type constructors (optionally also mapping in the process). Traversable It may be case that some function returns a list of Maybe s, i.e. [ Maybe a ] , but we may want Maybe [ a ] instead. Semantically, it may convey different meaning: a list of possible values is different from a possible list of values.","title":"Use Case"},{"location":"21-traversable/notes/#traversable-laws","text":"","title":"Traversable Laws"},{"location":"21-traversable/notes/#traverse_1","text":"Naturality . t . traverse f = traverse ( t . f ) Identity . traverse Identity = Identity Composition . traverse ( Compose . fmap g . f ) = Compose . fmap ( traverse g ) . traverse f","title":"traverse"},{"location":"21-traversable/notes/#sequencea_1","text":"The sequenceA must satisfy: Naturality . t . sequenceA = sequenceA . fmap t Identity . sequenceA . fmap Identity = Identity Composition . sequenceA . fmap Compose = Compose . fmap sequenceA . sequenceA","title":"sequenceA"},{"location":"22-reader/notes/","text":"Reader \u00b6","title":"Reader"},{"location":"22-reader/notes/#reader","text":"","title":"Reader"},{"location":"3-strings/notes/","text":"Strings \u00b6 Types \u00b6 Types are ways to categorize values. Finding type information using GHCi Prelude > : type 'a' 'a' :: Char For Strings, such as \"Hello World\" , Prelude > : type \"Hello World\" \"Hello World\" :: [ Char ] Here String is a type alias for [ Char ] , a list of characters. Printing Strings \u00b6 Functions such as print may be used to print String s and other data types to the console. putStr and putStrLn are specialized for String data type. IO Type \u00b6 The IO type standards for Input/Output, and represents effects which are not pure. Do syntax The do syntax sequences actions: main :: IO () main = do putStrLn \"1. action 1\" putStrLn \"2. action 2\" putStrLn \"3. action 3\" Concatenating Strings \u00b6 The concatenation operator ( ++ ) may be used to concat two strings (or lists of Char s together). It has the type signature ( ++ ) :: [ a ] -> [ a ] -> [ a ] That is, it takes two lists of some arbitary type a and combines them to give a single combined list of a s. Such arbitary type is a wildcard type, which can be any type. Since it is the same type variable a throughout, the input lists and output list must have elements of the same type a . String concatenation operator Prelude > \"Hello \" ++ \"World!\" Hello World ! The concat function can also be used to combine some Foldable list with elements of arbitary type a . concat :: Foldable t => t [ a ] -> [ a ] String concat Prelude > concat [ \"Hello\" , \" \" , \"World!\" ] Hello World ! Lists \u00b6 Prepend \u00b6 The cons operator ( : ) prepends an element to a list (of the same type). ( : ) :: a -> [ a ] -> [ a ] Getting first element \u00b6 The head function returns the first element of a list. head :: [ a ] -> a What if the list is empty? Haskell will through an exception should the list be empty. It may be wise to wrap the head function into a safeHead function where safeHead :: [ a ] -> Maybe a safeHead [] = Nothing safeHead ( x : xs ) = Just x Getting every element except for the first \u00b6 The tail function returns all elements but the first element of a list. tail :: [ a ] -> [ a ] Empty list Similar to head, Haskell will also throw exception if list is empty. A safe version safeTail can also be used where safeTail :: [ a ] -> Maybe [ a ] safeTail [] = Nothing safeTail ( x : xs ) = Just xs Getting some specified number of elements \u00b6 The take function returns a selected number of elements, counting from the left. take :: Int -> [ a ] -> [ a ] Keeping a specified number of elements \u00b6 The drop function discards a selected number of elements, counting from the left, and returns the remainder. drop :: Int -> [ a ] -> a Indexing \u00b6 The ( !! ) infix indexing operator returns the element in the specified position with the index starting from 0. ( !! ) :: [ a ] -> Int -> a","title":"Strings"},{"location":"3-strings/notes/#strings","text":"","title":"Strings"},{"location":"3-strings/notes/#types","text":"Types are ways to categorize values. Finding type information using GHCi Prelude > : type 'a' 'a' :: Char For Strings, such as \"Hello World\" , Prelude > : type \"Hello World\" \"Hello World\" :: [ Char ] Here String is a type alias for [ Char ] , a list of characters.","title":"Types"},{"location":"3-strings/notes/#printing-strings","text":"Functions such as print may be used to print String s and other data types to the console. putStr and putStrLn are specialized for String data type.","title":"Printing Strings"},{"location":"3-strings/notes/#io-type","text":"The IO type standards for Input/Output, and represents effects which are not pure. Do syntax The do syntax sequences actions: main :: IO () main = do putStrLn \"1. action 1\" putStrLn \"2. action 2\" putStrLn \"3. action 3\"","title":"IO Type"},{"location":"3-strings/notes/#concatenating-strings","text":"The concatenation operator ( ++ ) may be used to concat two strings (or lists of Char s together). It has the type signature ( ++ ) :: [ a ] -> [ a ] -> [ a ] That is, it takes two lists of some arbitary type a and combines them to give a single combined list of a s. Such arbitary type is a wildcard type, which can be any type. Since it is the same type variable a throughout, the input lists and output list must have elements of the same type a . String concatenation operator Prelude > \"Hello \" ++ \"World!\" Hello World ! The concat function can also be used to combine some Foldable list with elements of arbitary type a . concat :: Foldable t => t [ a ] -> [ a ] String concat Prelude > concat [ \"Hello\" , \" \" , \"World!\" ] Hello World !","title":"Concatenating Strings"},{"location":"3-strings/notes/#lists","text":"","title":"Lists"},{"location":"3-strings/notes/#prepend","text":"The cons operator ( : ) prepends an element to a list (of the same type). ( : ) :: a -> [ a ] -> [ a ]","title":"Prepend"},{"location":"3-strings/notes/#getting-first-element","text":"The head function returns the first element of a list. head :: [ a ] -> a What if the list is empty? Haskell will through an exception should the list be empty. It may be wise to wrap the head function into a safeHead function where safeHead :: [ a ] -> Maybe a safeHead [] = Nothing safeHead ( x : xs ) = Just x","title":"Getting first element"},{"location":"3-strings/notes/#getting-every-element-except-for-the-first","text":"The tail function returns all elements but the first element of a list. tail :: [ a ] -> [ a ] Empty list Similar to head, Haskell will also throw exception if list is empty. A safe version safeTail can also be used where safeTail :: [ a ] -> Maybe [ a ] safeTail [] = Nothing safeTail ( x : xs ) = Just xs","title":"Getting every element except for the first"},{"location":"3-strings/notes/#getting-some-specified-number-of-elements","text":"The take function returns a selected number of elements, counting from the left. take :: Int -> [ a ] -> [ a ]","title":"Getting some specified number of elements"},{"location":"3-strings/notes/#keeping-a-specified-number-of-elements","text":"The drop function discards a selected number of elements, counting from the left, and returns the remainder. drop :: Int -> [ a ] -> a","title":"Keeping a specified number of elements"},{"location":"3-strings/notes/#indexing","text":"The ( !! ) infix indexing operator returns the element in the specified position with the index starting from 0. ( !! ) :: [ a ] -> Int -> a","title":"Indexing"},{"location":"4-basic-datatypes/notes/","text":"Basic Datatypes \u00b6 Types (Datatypes) \u00b6 Types (or datatypes ) introduces discipline in the inputs and outputs of functions. They restrict what inputs and outputs can be \u2014 which provides valuable information. Types, when used properly, can help to accomplish more with less code. Types are how similar values are grouped together by finding commonality. Such commonality may be abstract. Data declaration \u00b6 A type may be declared with: Datatypes are defined via data declarations . Type constructor is the name of the type. Data constructors are the values which may show up at the term level instead of the type level . Bool Type \u00b6 The datatype Bool represents the boolean values. data Bool = False | True Bool is the name of the type, and is the type constructor . False and True are the two value constructors which are the only possible values that the Bool type may take. The pipe | indicates sum type (i.e. either False or True ). Numeric Types \u00b6 Haskell has multiple numeric types, but the commonly used ones can be classified into Integral numbers and Fractional numbers. Integral numbers: Int : fixed-precision integer. Integer : arbitary-precision integer. Fractional numbers: Float : single-precision floating point number. Double : double-precision floating point number. Rational : fractional number which represents ratio between two integers; arbitary precision. Scientific : space-efficient and almost-arbitary-precision, represented via Scientific notation, with the coefficient being Integer and exponent as Int . All of such numeric types are instances of the Num typeclass . A typeclass adds functionality to types which shall be shared by instances of such typeclass. Num is the typeclass for these numeric types as the numbers share operations such as ( + ) , ( - ) , ( * ) . Each instance specifies how such operations behave with respect to the type. The minBound and maxBound functions can be used to find the min and max bounds for numeric types which are instances of the Bounded typeclass. Comparing Values \u00b6 Testing for equality (inequality) between two values which are of types that are instances of the Eq typeclass (i.e. values which have the notion of \"equality\"): -- Equality ( == ) :: Eq a => a -> a -> Bool -- Inequality ( /= ) :: Eq a => a -> a -> Bool Testing for order (less than, more than) between two values which are of types that are instances of the Ord typeclass (i.e. values which have the notion of \"order\"). -- Less than ( < ) :: Ord a => a -> a -> Bool -- More than ( > ) :: Ord a => a -> a -> Bool Bool Functions and Operators \u00b6 The boolean algebra functions and operators: -- Negation / not not :: Bool -> Bool -- And ( && ) :: Bool -> Bool -> Bool -- Or ( || ) :: Bool -> Bool -> Bool Conditionals \u00b6 Haskell only has if expressions but not statements: if CONDITION then EXPRESSION_A else EXPRESSION_B This expression reduces to EXPRESSION_A or EXPRESSION_B depending on the CONDITION . It is similar to ternary expressions in other languages such as JavaScript: ( 1 + 1 == 2 ) ? \"Hello World\" : \"Goodbye World\" ; // -> \"Hello World\" Tuples \u00b6 Tuples allows combining multiple values grouped up in one value. It is also known as a product type , which represents conjunction \u2014 all constituents are required to successfully construct the tuple type. A n-tuple is said to have n constituents. For exmaple, a 2-tuple has two components, (x, y) . The number of constituents of a tuple is known as its arity . Constituents of a tuple do not have to be of the same type. 2-tuple \u00b6 A 2-tuple's datatype declaration is given by: (,) :: a -> b -> ( a , b ) And also data (,) a b = (,) a b Convience functions, namely fst and snd allows easy extraction of the first and second values out of the tuple respectively. fst :: ( a , b ) -> a snd :: ( a , b ) -> b","title":"Basic Datatypes"},{"location":"4-basic-datatypes/notes/#basic-datatypes","text":"","title":"Basic Datatypes"},{"location":"4-basic-datatypes/notes/#types-datatypes","text":"Types (or datatypes ) introduces discipline in the inputs and outputs of functions. They restrict what inputs and outputs can be \u2014 which provides valuable information. Types, when used properly, can help to accomplish more with less code. Types are how similar values are grouped together by finding commonality. Such commonality may be abstract.","title":"Types (Datatypes)"},{"location":"4-basic-datatypes/notes/#data-declaration","text":"A type may be declared with: Datatypes are defined via data declarations . Type constructor is the name of the type. Data constructors are the values which may show up at the term level instead of the type level .","title":"Data declaration"},{"location":"4-basic-datatypes/notes/#bool-type","text":"The datatype Bool represents the boolean values. data Bool = False | True Bool is the name of the type, and is the type constructor . False and True are the two value constructors which are the only possible values that the Bool type may take. The pipe | indicates sum type (i.e. either False or True ).","title":"Bool Type"},{"location":"4-basic-datatypes/notes/#numeric-types","text":"Haskell has multiple numeric types, but the commonly used ones can be classified into Integral numbers and Fractional numbers. Integral numbers: Int : fixed-precision integer. Integer : arbitary-precision integer. Fractional numbers: Float : single-precision floating point number. Double : double-precision floating point number. Rational : fractional number which represents ratio between two integers; arbitary precision. Scientific : space-efficient and almost-arbitary-precision, represented via Scientific notation, with the coefficient being Integer and exponent as Int . All of such numeric types are instances of the Num typeclass . A typeclass adds functionality to types which shall be shared by instances of such typeclass. Num is the typeclass for these numeric types as the numbers share operations such as ( + ) , ( - ) , ( * ) . Each instance specifies how such operations behave with respect to the type. The minBound and maxBound functions can be used to find the min and max bounds for numeric types which are instances of the Bounded typeclass.","title":"Numeric Types"},{"location":"4-basic-datatypes/notes/#comparing-values","text":"Testing for equality (inequality) between two values which are of types that are instances of the Eq typeclass (i.e. values which have the notion of \"equality\"): -- Equality ( == ) :: Eq a => a -> a -> Bool -- Inequality ( /= ) :: Eq a => a -> a -> Bool Testing for order (less than, more than) between two values which are of types that are instances of the Ord typeclass (i.e. values which have the notion of \"order\"). -- Less than ( < ) :: Ord a => a -> a -> Bool -- More than ( > ) :: Ord a => a -> a -> Bool","title":"Comparing Values"},{"location":"4-basic-datatypes/notes/#bool-functions-and-operators","text":"The boolean algebra functions and operators: -- Negation / not not :: Bool -> Bool -- And ( && ) :: Bool -> Bool -> Bool -- Or ( || ) :: Bool -> Bool -> Bool","title":"Bool Functions and Operators"},{"location":"4-basic-datatypes/notes/#conditionals","text":"Haskell only has if expressions but not statements: if CONDITION then EXPRESSION_A else EXPRESSION_B This expression reduces to EXPRESSION_A or EXPRESSION_B depending on the CONDITION . It is similar to ternary expressions in other languages such as JavaScript: ( 1 + 1 == 2 ) ? \"Hello World\" : \"Goodbye World\" ; // -> \"Hello World\"","title":"Conditionals"},{"location":"4-basic-datatypes/notes/#tuples","text":"Tuples allows combining multiple values grouped up in one value. It is also known as a product type , which represents conjunction \u2014 all constituents are required to successfully construct the tuple type. A n-tuple is said to have n constituents. For exmaple, a 2-tuple has two components, (x, y) . The number of constituents of a tuple is known as its arity . Constituents of a tuple do not have to be of the same type.","title":"Tuples"},{"location":"4-basic-datatypes/notes/#2-tuple","text":"A 2-tuple's datatype declaration is given by: (,) :: a -> b -> ( a , b ) And also data (,) a b = (,) a b Convience functions, namely fst and snd allows easy extraction of the first and second values out of the tuple respectively. fst :: ( a , b ) -> a snd :: ( a , b ) -> b","title":"2-tuple"},{"location":"5-types/notes/","text":"Types \u00b6 Haskell implements pure (typed) lambda calculus. Haskell improves on System F and Hindley-Milner type system for type inference. Type systems enforce enstrictions to ensure correctness. Haskell is statically typed, meaning types are checked at compile time, catching errors early. Types can also help optimizations. Types are good documentation. Type Polymorphism \u00b6 Type variables such as Num a => a can be constrained. Here, type a is required to be an instance of the Num typeclass. This is called constrained polymorphism. Such a is called a typeclass-constrained type variable. Function Type \u00b6 The arrow operator ( -> ) is the type constructor for functions. data ( -> ) a b Typeclass Constraints \u00b6 As previously mentioned, a polymorphic type variable may be constrained by typeclass(-es). Num a => a ( Num a , Num b ) => a -> b -> b Currying \u00b6 Currying allows the innermost body expression to have access to the value of multiple arguments by nesting lambdas (even though each lambda only has one argument). Having some function such as fn :: a -> a -> a When one argument is supplied to fn , a new function of type a -> a is returned with the previous argument filled in. fn :: a -> ( a -> a ) Would be more accurate, but since ( -> ) is right associative, the parentheses may be dropped. Functions can also take other functions as argument (i.e. higher-order functions ). map :: ( a -> b ) -> [ a ] -> [ b ] Here the parentheses is necessary to group the ( a -> b ) part to designate it as a function as single argument and not two distinct arguments. Partial Application \u00b6 If some function is curried, e.g. map , then part of the arguments can be filled in. For example, we can supply the identity function id x = x to map . id :: a -> a id x = x mapId :: [ a ] -> [ b ] mapId xs = map id xs Notice that: map id , map applied to id , has the type [ a ] -> [ b ] which is identical to that of mapId . mapId does nothing to xs apart from passing it to map id . This means that xs can be omitted, and mapId can simply be defined as an alias to the partiall-applied map id . mapId :: [ a ] -> [ b ] mapId = map id This is called point-free style. Sectioning \u00b6 Partially applying infix operators is called sectioning . Sectioning addOne :: Num a => a -> a addOne = ( + 1 ) Here ( + 1 ) is the addition ( + ) partially applied with 1 . Since ( + ) is commutative, ( + 1 ) == ( 1 + ) , but ( - 2 ) /= ( 2 - ) since ( - ) is not commutative. Polymorphism \u00b6 Polymorphic type variables allows expressions to work with arbitary types, so we don't need to implement such expression for every type we need to it work with. Haskell polymorphism is classified into: Parametric polymorphism . Constrained polymorphism . Parametric polymorphism is more broad than constrained polymorphism since it places less restrictions. The identity function id :: a -> a Is maximally polymorphic since it works with any data. But id cannot do anything with a other than to return it because it has no information on a . When the type variable is constrained by a typeclass, it can take less types but also comes with a set of operations which can be used on the argument. Concrete types can be instances of multiple typeclasses, and typeclasses can be superclasses of typeclasses. Such typeclasses are additive in nature in that by becoming instances of typeclasses, one inherits their defined operations. Type Inference \u00b6 Haskell's type inference is extended from the Damas-Hindley-Milner type system. Haskell tries to infer the most polymorphic / general type possible while ensuring correctness.","title":"Types"},{"location":"5-types/notes/#types","text":"Haskell implements pure (typed) lambda calculus. Haskell improves on System F and Hindley-Milner type system for type inference. Type systems enforce enstrictions to ensure correctness. Haskell is statically typed, meaning types are checked at compile time, catching errors early. Types can also help optimizations. Types are good documentation.","title":"Types"},{"location":"5-types/notes/#type-polymorphism","text":"Type variables such as Num a => a can be constrained. Here, type a is required to be an instance of the Num typeclass. This is called constrained polymorphism. Such a is called a typeclass-constrained type variable.","title":"Type Polymorphism"},{"location":"5-types/notes/#function-type","text":"The arrow operator ( -> ) is the type constructor for functions. data ( -> ) a b","title":"Function Type"},{"location":"5-types/notes/#typeclass-constraints","text":"As previously mentioned, a polymorphic type variable may be constrained by typeclass(-es). Num a => a ( Num a , Num b ) => a -> b -> b","title":"Typeclass Constraints"},{"location":"5-types/notes/#currying","text":"Currying allows the innermost body expression to have access to the value of multiple arguments by nesting lambdas (even though each lambda only has one argument). Having some function such as fn :: a -> a -> a When one argument is supplied to fn , a new function of type a -> a is returned with the previous argument filled in. fn :: a -> ( a -> a ) Would be more accurate, but since ( -> ) is right associative, the parentheses may be dropped. Functions can also take other functions as argument (i.e. higher-order functions ). map :: ( a -> b ) -> [ a ] -> [ b ] Here the parentheses is necessary to group the ( a -> b ) part to designate it as a function as single argument and not two distinct arguments.","title":"Currying"},{"location":"5-types/notes/#partial-application","text":"If some function is curried, e.g. map , then part of the arguments can be filled in. For example, we can supply the identity function id x = x to map . id :: a -> a id x = x mapId :: [ a ] -> [ b ] mapId xs = map id xs Notice that: map id , map applied to id , has the type [ a ] -> [ b ] which is identical to that of mapId . mapId does nothing to xs apart from passing it to map id . This means that xs can be omitted, and mapId can simply be defined as an alias to the partiall-applied map id . mapId :: [ a ] -> [ b ] mapId = map id This is called point-free style.","title":"Partial Application"},{"location":"5-types/notes/#sectioning","text":"Partially applying infix operators is called sectioning . Sectioning addOne :: Num a => a -> a addOne = ( + 1 ) Here ( + 1 ) is the addition ( + ) partially applied with 1 . Since ( + ) is commutative, ( + 1 ) == ( 1 + ) , but ( - 2 ) /= ( 2 - ) since ( - ) is not commutative.","title":"Sectioning"},{"location":"5-types/notes/#polymorphism","text":"Polymorphic type variables allows expressions to work with arbitary types, so we don't need to implement such expression for every type we need to it work with. Haskell polymorphism is classified into: Parametric polymorphism . Constrained polymorphism . Parametric polymorphism is more broad than constrained polymorphism since it places less restrictions. The identity function id :: a -> a Is maximally polymorphic since it works with any data. But id cannot do anything with a other than to return it because it has no information on a . When the type variable is constrained by a typeclass, it can take less types but also comes with a set of operations which can be used on the argument. Concrete types can be instances of multiple typeclasses, and typeclasses can be superclasses of typeclasses. Such typeclasses are additive in nature in that by becoming instances of typeclasses, one inherits their defined operations.","title":"Polymorphism"},{"location":"5-types/notes/#type-inference","text":"Haskell's type inference is extended from the Damas-Hindley-Milner type system. Haskell tries to infer the most polymorphic / general type possible while ensuring correctness.","title":"Type Inference"},{"location":"6-typeclasses/notes/","text":"Typeclasses \u00b6 Type declaration specifies how a type is created , but typeclass declaration specifies how a set of types are consumed (creation versus usage). Typeclasses are like interfaces in different languages - which allows reuse of functionality across multiple datatypes. Typeclasses allow generalization of shared features: e.g. Eq typeclass instances can be tested for equality. Bool \u00b6 The data type Bool is declared to be instances of many typeclasses: Prelude > : info Bool data Bool = False | True instance Bounded Bool instance Enum Bool instance Eq Bool instance Ord Bool instance Read Bool instance Show Bool Eq \u00b6 Equality in Haskell is expressed by implementing the Eq typeclass. The Eq typeclass is defined as Prelude > : info Eq class Eq a where ( == ) :: a -> a -> Bool ( /= ) :: a -> a -> Bool Such typeclass definition tells us that any types implementing it is required to supply definitions for ( == ) and ( /= ) , and code using Eq as constraints can rely on the equals-to and not-equals-to operations being defined on the supplied arguments. GHCi also lists its instances: instance Eq a => Eq [ a ] instance Eq Ordering instance Eq Int instance Eq Float instance Eq Double instance Eq Char instance Eq Bool instance ( Eq a , Eq b ) => Eq ( a , b ) instance Eq () instance Eq a => Eq ( Maybe a ) instance Eq Integer Defining Typeclass Instances \u00b6 Eq Instances \u00b6 Each typeclass has a minimal complete definition . For Eq , it is either ( == ) or ( /= ) . Both are provided as part of the definition since it may be possible that the definition for each contains opportunity to optimize independently. Trivial datatype data Trivial = Trivial' instance Eq Trivial where Trivial' == Trivial' = True Weekday data DayOfWeek = Monday | Tuesday | Wednesday | Thursday | Friday | Saturday | Sunday data Date = Date DayOfWeek Int instance Eq DayOfWeek where ( == ) Monday Monday = True ( == ) Tuesday Tuesday = True ( == ) Wednesday Wednesday = True ( == ) Thursday Thursday = True ( == ) Friday Friday = True ( == ) Saturday Saturday = True ( == ) Sunday Sunday = True ( == ) _ _ = False instance Eq Date where ( == ) ( Date weekDay dayOfMonth ) ( Date weekDay' dayOfMonth' ) = weekDay == weekDay' && dayOfMonth == dayOfMonth' Partial Functions \u00b6 Sometimes not all possible cases are handled. This danger can be mitigated by turning on -Wall warning flags in the GHC. Typeclasses with Additional Arguments \u00b6 Identity typeclass data Identity a = Identity a instance Eq a => Eq ( Identity a ) where ( == ) ( Identity v ) ( Identity v' ) = v == v' Num Typeclass \u00b6 class Num a where ( + ) :: a -> a -> a ( * ) :: a -> a -> a ( - ) :: a -> a -> a negate :: a -> a abs :: a -> a signum :: a -> a fromInteger :: Integer -> a Some of its instances include: instance Num Integer instance Num Int instance Num Float instance Num Double Integral Typeclass \u00b6 class ( Real a , Enum a ) => Integral a where quot :: a -> a -> a rem :: a -> a -> a div :: a -> a -> a mod :: a -> a -> a quotRem :: a -> a -> ( a , a ) divMod :: a -> a -> ( a , a ) toInteger :: a -> Integer Fractional Typeclass \u00b6 class Num a => Fractional a where ( / ) :: a -> a -> a recip :: a -> a fromRational :: Rational -> a Ord Typeclass \u00b6 class Eq a => Ord a where compare :: a -> a -> Ordering ( < ) :: a -> a -> Bool ( <= ) :: a -> a -> Bool ( > ) :: a -> a -> Bool ( >= ) :: a -> a -> Bool max :: a -> a -> a min :: a -> a -> a Notable instances include: instance Ord a => Ord ( Maybe a ) instance ( Ord a , Ord b ) => Ord ( Either a b ) instance Ord Integer instance Ord a => Ord [ a ] instance Ord Ordering instance Ord Int instance Ord Float instance Ord Double instance Ord Char instance Ord Bool Since ordering requires equality, Ord is a subclass of Eq . Enum Typeclass \u00b6 The Enum typeclass describes types which are enumerable; types for which there exists known precedessors and successors. class Enum a where succ :: a -> a pred :: a -> a toEnum :: Int -> a fromEnum :: a -> Int enumFrom :: a -> [ a ] enumFromThen :: a -> a -> [ a ] enumFromTo :: a -> a -> [ a ] enumFromThenTo :: a -> a -> a -> [ a ] Some notable instances include: instance Enum Ordering instance Enum Integer instance Enum Int instance Enum Char instance Enum Bool instance Enum () instance Enum Float instance Enum Double Show \u00b6 The Show typeclass specifies how human-readable string representations of data types are created. Not for serialization The Show typeclass must not be used for serialization; it must only be used for debugging purposes and for creating human-readable representations. The Show typeclass' essential part is defined as class Show a where showsPrec :: Int -> a -> ShowS show :: a -> String showList :: [ a ] -> ShowS With notable instances including: instance Show a => Show [ a ] instance Show Ordering instance Show a => Show ( Maybe a ) instance Show Integer instance Show Int instance Show Char instance Show Bool instance Show () instance Show Float instance Show Double Printing and Side Effects \u00b6 The print function defined in Prelude is defined with the type print :: Show a => a -> IO () The result is an IO action with the value of type () . The entry point main is also required to have the return type of some IO a with a being some arbitary type, since running main only produces side-effects. The () is an empty tuple, read as an \" Unit \", representing lack of meaningful value. Read Typeclass \u00b6 Avoid using Read The Read typeclass's read function is defined with type read :: Read a => String -> a But not every string can be successfully parsed into the desired value; it is most likely a partial function and as such may throw exceptions. Typeclass Dispatching \u00b6 Typeclasses are dispatched by type. Typeclasses are defined by set of operations and values all of its instances provide. Typeclass instances pair the typeclass with a specific type and are the ways to implement the typeclass methods for the type. Typeclass Inheritance Hierarchy (Partial) \u00b6","title":"Typeclasses"},{"location":"6-typeclasses/notes/#typeclasses","text":"Type declaration specifies how a type is created , but typeclass declaration specifies how a set of types are consumed (creation versus usage). Typeclasses are like interfaces in different languages - which allows reuse of functionality across multiple datatypes. Typeclasses allow generalization of shared features: e.g. Eq typeclass instances can be tested for equality.","title":"Typeclasses"},{"location":"6-typeclasses/notes/#bool","text":"The data type Bool is declared to be instances of many typeclasses: Prelude > : info Bool data Bool = False | True instance Bounded Bool instance Enum Bool instance Eq Bool instance Ord Bool instance Read Bool instance Show Bool","title":"Bool"},{"location":"6-typeclasses/notes/#eq","text":"Equality in Haskell is expressed by implementing the Eq typeclass. The Eq typeclass is defined as Prelude > : info Eq class Eq a where ( == ) :: a -> a -> Bool ( /= ) :: a -> a -> Bool Such typeclass definition tells us that any types implementing it is required to supply definitions for ( == ) and ( /= ) , and code using Eq as constraints can rely on the equals-to and not-equals-to operations being defined on the supplied arguments. GHCi also lists its instances: instance Eq a => Eq [ a ] instance Eq Ordering instance Eq Int instance Eq Float instance Eq Double instance Eq Char instance Eq Bool instance ( Eq a , Eq b ) => Eq ( a , b ) instance Eq () instance Eq a => Eq ( Maybe a ) instance Eq Integer","title":"Eq"},{"location":"6-typeclasses/notes/#defining-typeclass-instances","text":"","title":"Defining Typeclass Instances"},{"location":"6-typeclasses/notes/#eq-instances","text":"Each typeclass has a minimal complete definition . For Eq , it is either ( == ) or ( /= ) . Both are provided as part of the definition since it may be possible that the definition for each contains opportunity to optimize independently. Trivial datatype data Trivial = Trivial' instance Eq Trivial where Trivial' == Trivial' = True Weekday data DayOfWeek = Monday | Tuesday | Wednesday | Thursday | Friday | Saturday | Sunday data Date = Date DayOfWeek Int instance Eq DayOfWeek where ( == ) Monday Monday = True ( == ) Tuesday Tuesday = True ( == ) Wednesday Wednesday = True ( == ) Thursday Thursday = True ( == ) Friday Friday = True ( == ) Saturday Saturday = True ( == ) Sunday Sunday = True ( == ) _ _ = False instance Eq Date where ( == ) ( Date weekDay dayOfMonth ) ( Date weekDay' dayOfMonth' ) = weekDay == weekDay' && dayOfMonth == dayOfMonth'","title":"Eq Instances"},{"location":"6-typeclasses/notes/#partial-functions","text":"Sometimes not all possible cases are handled. This danger can be mitigated by turning on -Wall warning flags in the GHC.","title":"Partial Functions"},{"location":"6-typeclasses/notes/#typeclasses-with-additional-arguments","text":"Identity typeclass data Identity a = Identity a instance Eq a => Eq ( Identity a ) where ( == ) ( Identity v ) ( Identity v' ) = v == v'","title":"Typeclasses with Additional Arguments"},{"location":"6-typeclasses/notes/#num-typeclass","text":"class Num a where ( + ) :: a -> a -> a ( * ) :: a -> a -> a ( - ) :: a -> a -> a negate :: a -> a abs :: a -> a signum :: a -> a fromInteger :: Integer -> a Some of its instances include: instance Num Integer instance Num Int instance Num Float instance Num Double","title":"Num Typeclass"},{"location":"6-typeclasses/notes/#integral-typeclass","text":"class ( Real a , Enum a ) => Integral a where quot :: a -> a -> a rem :: a -> a -> a div :: a -> a -> a mod :: a -> a -> a quotRem :: a -> a -> ( a , a ) divMod :: a -> a -> ( a , a ) toInteger :: a -> Integer","title":"Integral Typeclass"},{"location":"6-typeclasses/notes/#fractional-typeclass","text":"class Num a => Fractional a where ( / ) :: a -> a -> a recip :: a -> a fromRational :: Rational -> a","title":"Fractional Typeclass"},{"location":"6-typeclasses/notes/#ord-typeclass","text":"class Eq a => Ord a where compare :: a -> a -> Ordering ( < ) :: a -> a -> Bool ( <= ) :: a -> a -> Bool ( > ) :: a -> a -> Bool ( >= ) :: a -> a -> Bool max :: a -> a -> a min :: a -> a -> a Notable instances include: instance Ord a => Ord ( Maybe a ) instance ( Ord a , Ord b ) => Ord ( Either a b ) instance Ord Integer instance Ord a => Ord [ a ] instance Ord Ordering instance Ord Int instance Ord Float instance Ord Double instance Ord Char instance Ord Bool Since ordering requires equality, Ord is a subclass of Eq .","title":"Ord Typeclass"},{"location":"6-typeclasses/notes/#enum-typeclass","text":"The Enum typeclass describes types which are enumerable; types for which there exists known precedessors and successors. class Enum a where succ :: a -> a pred :: a -> a toEnum :: Int -> a fromEnum :: a -> Int enumFrom :: a -> [ a ] enumFromThen :: a -> a -> [ a ] enumFromTo :: a -> a -> [ a ] enumFromThenTo :: a -> a -> a -> [ a ] Some notable instances include: instance Enum Ordering instance Enum Integer instance Enum Int instance Enum Char instance Enum Bool instance Enum () instance Enum Float instance Enum Double","title":"Enum Typeclass"},{"location":"6-typeclasses/notes/#show","text":"The Show typeclass specifies how human-readable string representations of data types are created. Not for serialization The Show typeclass must not be used for serialization; it must only be used for debugging purposes and for creating human-readable representations. The Show typeclass' essential part is defined as class Show a where showsPrec :: Int -> a -> ShowS show :: a -> String showList :: [ a ] -> ShowS With notable instances including: instance Show a => Show [ a ] instance Show Ordering instance Show a => Show ( Maybe a ) instance Show Integer instance Show Int instance Show Char instance Show Bool instance Show () instance Show Float instance Show Double","title":"Show"},{"location":"6-typeclasses/notes/#printing-and-side-effects","text":"The print function defined in Prelude is defined with the type print :: Show a => a -> IO () The result is an IO action with the value of type () . The entry point main is also required to have the return type of some IO a with a being some arbitary type, since running main only produces side-effects. The () is an empty tuple, read as an \" Unit \", representing lack of meaningful value.","title":"Printing and Side Effects"},{"location":"6-typeclasses/notes/#read-typeclass","text":"Avoid using Read The Read typeclass's read function is defined with type read :: Read a => String -> a But not every string can be successfully parsed into the desired value; it is most likely a partial function and as such may throw exceptions.","title":"Read Typeclass"},{"location":"6-typeclasses/notes/#typeclass-dispatching","text":"Typeclasses are dispatched by type. Typeclasses are defined by set of operations and values all of its instances provide. Typeclass instances pair the typeclass with a specific type and are the ways to implement the typeclass methods for the type.","title":"Typeclass Dispatching"},{"location":"6-typeclasses/notes/#typeclass-inheritance-hierarchy-partial","text":"","title":"Typeclass Inheritance Hierarchy (Partial)"},{"location":"7-functional-patterns/notes/","text":"Functional Patterns \u00b6 Anonymous Functions \u00b6 Anonymous function syntax addOne :: Integer -> Integer addOne x = x + 1 Is identical to ( \\ x -> x + 1 ) :: Integer -> Integer Anonymous functions are useful especially when used as arguments passed to higher order functions. Anonymous function as argument addEach :: Integer -> [ Integer ] -> [ Integer ] addEach value xs = map ( \\ x -> x + value ) xs -- or equivalently using sectioning addEach' :: Integer -> [ Integer ] -> [ Integer ] addEach' value xs = map ( + value ) xs -- since xs is simply passed on to map addEach'' :: Integer -> [ Integer ] -> [ Integer ] addEach'' value = map ( + value ) Pattern Matching \u00b6 Patterns are matched against values or data constructors and not types. Pattern matching allows destructing arguments to check for desired patterns; should the desired pattern exist, the value will be matched and bound to named variables. Pattern matching numbers isZero :: Integer -> Bool isZero 0 = True isZero _ = False Order of definition affects pattern matching Wildcard pattern _ should always be the last case, otherwise it will unconditionally catch every possible input. isZero :: Integer -> Bool isZero _ = False isZero 0 = True Will always give False even if the input is 0 . That last case isZero 0 = True will never be reached. GHCi will provide warning for such overlapped patterns; but the programmer shall take care to order the cases from the most specific to the most generic. Bottom will be returned if pattern matching is non-exhaustive If not all cases are handled for all possible input values, the bottom value (which expresses a non-value) will be returned and an expcetion will be thrown. Pattern matching against data constructors module User where newtype UserId = UserId Integer newtype UserName = UserName String data User = UnregisteredUser | RegisteredUser UserId UserName Since User has two data constructors, we can pattern matching against both. showInfo :: User -> String showInfo ( UnregisteredUser ) = \"Unregistered\" showInfo ( RegisteredUser id name ) = \"Registerd user: { \" ++ ( show id ) ++ name ++ \"}\" Newtype The newtype keyword allows declaring a datatype with only one data constructor; it is more efficient than the data declaration but is more restrictive. Pattern matching tuples f :: ( Integer , Bool ) -> Bool f ( i , b ) = if ( i > 0 && b ) then True else False Case Expressions \u00b6 Case expression matching on Bool pluralize :: Integer -> String pluralize i = case i > 1 of True -> \"s\" False -> \"\" Palindrome check isPalindrome :: String -> String isPalindrome xs = case xs == reverse xs of True -> \"Yes\" False -> \"No\" Guards \u00b6 Absolute value abs' :: Integer -> Integer abs' n | n < 0 = ( - n ) | otherwise = n Like pattern matching, the order of the branches also matters, with matching occuring top-to-down. Right triangle isRightTriangle :: ( Num a , Eq a ) => a -> a -> a -> Bool isRightTriangle a b c | a ^ 2 + b ^ 2 == c ^ 2 = True | otherwise = False Function Composition \u00b6 The composition function ( . ) has the signature ( . ) :: ( b -> c ) -> ( a -> b ) -> a -> c It takes two functions and an argument: It takes a function f :: b -> c . It takes a function g :: a -> b . It takes an argument x :: a . The composition function applies x to the first function g , and takes the output from g and feeds it to f . With parentheses, ( . ) :: ( b -> c ) -> ( a -> b ) -> ( a -> c ) The composition function takes two functions and creates a new function which is the combination of the two input functions: It takes a function f :: b -> c . It takes a function g :: a -> b . It creates and returns a new function h :: a -> c . That is, ( f . g ) x == f ( g x ) Note that the composition function ( . ) is right associative. As such, ( f . g . h ) x == f ( g ( h x )) Point-free Style \u00b6 Point-free style refers to composing functions without specifying their parameters \u2013 this helps to place emphasize on the functions. ( f . g . h ) x == f ( g ( h x )) -- equivalent to f . g . h == \\ x -> f ( g ( h x )) Point-free function f :: Int -> [ Int ] -> Int f z xs = foldr ( + ) z xs -- equivalent to f' :: Int -> [ Int ] -> Int f' = foldr ( + ) Point-free function countChar :: [ Char ] -> Integer countChar c = length . filter ( == c ) countAs :: [ Char ] -> Integer countAs = countChar 'a'","title":"Functional Patterns"},{"location":"7-functional-patterns/notes/#functional-patterns","text":"","title":"Functional Patterns"},{"location":"7-functional-patterns/notes/#anonymous-functions","text":"Anonymous function syntax addOne :: Integer -> Integer addOne x = x + 1 Is identical to ( \\ x -> x + 1 ) :: Integer -> Integer Anonymous functions are useful especially when used as arguments passed to higher order functions. Anonymous function as argument addEach :: Integer -> [ Integer ] -> [ Integer ] addEach value xs = map ( \\ x -> x + value ) xs -- or equivalently using sectioning addEach' :: Integer -> [ Integer ] -> [ Integer ] addEach' value xs = map ( + value ) xs -- since xs is simply passed on to map addEach'' :: Integer -> [ Integer ] -> [ Integer ] addEach'' value = map ( + value )","title":"Anonymous Functions"},{"location":"7-functional-patterns/notes/#pattern-matching","text":"Patterns are matched against values or data constructors and not types. Pattern matching allows destructing arguments to check for desired patterns; should the desired pattern exist, the value will be matched and bound to named variables. Pattern matching numbers isZero :: Integer -> Bool isZero 0 = True isZero _ = False Order of definition affects pattern matching Wildcard pattern _ should always be the last case, otherwise it will unconditionally catch every possible input. isZero :: Integer -> Bool isZero _ = False isZero 0 = True Will always give False even if the input is 0 . That last case isZero 0 = True will never be reached. GHCi will provide warning for such overlapped patterns; but the programmer shall take care to order the cases from the most specific to the most generic. Bottom will be returned if pattern matching is non-exhaustive If not all cases are handled for all possible input values, the bottom value (which expresses a non-value) will be returned and an expcetion will be thrown. Pattern matching against data constructors module User where newtype UserId = UserId Integer newtype UserName = UserName String data User = UnregisteredUser | RegisteredUser UserId UserName Since User has two data constructors, we can pattern matching against both. showInfo :: User -> String showInfo ( UnregisteredUser ) = \"Unregistered\" showInfo ( RegisteredUser id name ) = \"Registerd user: { \" ++ ( show id ) ++ name ++ \"}\" Newtype The newtype keyword allows declaring a datatype with only one data constructor; it is more efficient than the data declaration but is more restrictive. Pattern matching tuples f :: ( Integer , Bool ) -> Bool f ( i , b ) = if ( i > 0 && b ) then True else False","title":"Pattern Matching"},{"location":"7-functional-patterns/notes/#case-expressions","text":"Case expression matching on Bool pluralize :: Integer -> String pluralize i = case i > 1 of True -> \"s\" False -> \"\" Palindrome check isPalindrome :: String -> String isPalindrome xs = case xs == reverse xs of True -> \"Yes\" False -> \"No\"","title":"Case Expressions"},{"location":"7-functional-patterns/notes/#guards","text":"Absolute value abs' :: Integer -> Integer abs' n | n < 0 = ( - n ) | otherwise = n Like pattern matching, the order of the branches also matters, with matching occuring top-to-down. Right triangle isRightTriangle :: ( Num a , Eq a ) => a -> a -> a -> Bool isRightTriangle a b c | a ^ 2 + b ^ 2 == c ^ 2 = True | otherwise = False","title":"Guards"},{"location":"7-functional-patterns/notes/#function-composition","text":"The composition function ( . ) has the signature ( . ) :: ( b -> c ) -> ( a -> b ) -> a -> c It takes two functions and an argument: It takes a function f :: b -> c . It takes a function g :: a -> b . It takes an argument x :: a . The composition function applies x to the first function g , and takes the output from g and feeds it to f . With parentheses, ( . ) :: ( b -> c ) -> ( a -> b ) -> ( a -> c ) The composition function takes two functions and creates a new function which is the combination of the two input functions: It takes a function f :: b -> c . It takes a function g :: a -> b . It creates and returns a new function h :: a -> c . That is, ( f . g ) x == f ( g x ) Note that the composition function ( . ) is right associative. As such, ( f . g . h ) x == f ( g ( h x ))","title":"Function Composition"},{"location":"7-functional-patterns/notes/#point-free-style","text":"Point-free style refers to composing functions without specifying their parameters \u2013 this helps to place emphasize on the functions. ( f . g . h ) x == f ( g ( h x )) -- equivalent to f . g . h == \\ x -> f ( g ( h x )) Point-free function f :: Int -> [ Int ] -> Int f z xs = foldr ( + ) z xs -- equivalent to f' :: Int -> [ Int ] -> Int f' = foldr ( + ) Point-free function countChar :: [ Char ] -> Integer countChar c = length . filter ( == c ) countAs :: [ Char ] -> Integer countAs = countChar 'a'","title":"Point-free Style"},{"location":"8-recursion/notes/","text":"Recursion \u00b6 To understand recursion scroll to the bottom of this page. Recursion refers to defining a function with regard to itself using self-referential expressions \u2013 the function will keep on calling itself unless some condition is reached, or else it never terminates (theoretically). Lambda calculus do not have recursion since expressions are nameless and so cannot be called. But to achieve Turing completeness, one needs to be able to write recursive functions. The Y combinator or fixed-point combinator is used to write recursive functions in lambda calculus. Factorial \u00b6 Broken Factorial A na\u00efve implementation of the factorial function may be: brokenFactorial :: Integer -> Integer brokenFactorial n = n * brokenFactorial ( n - 1 ) But trying to apply this function to any integer never terminates... brokenFactorial 3 = 3 * ( 3 - 1 ) * (( 3 - 1 ) - 1 ) * ... Because this implementation has No Base Case\u2122 . Better Factorial A better implementation for factorial may be: factorial :: Integer -> Integer factorial 0 = 1 factorial n = n * factorial ( n - 1 ) Which will terminate because eventually the base case will be reached and no more calls to itself will be made. factorial 3 = 3 * ( factorial 2 ) = 3 * ( 2 * ( factorial 1 )) = 3 * ( 2 * ( 1 * ( factorial 0 ))) = 3 * ( 2 * ( 1 * ( 1 ))) = 3 * ( 2 * ( 1 * 1 )) = 3 * ( 2 * ( 1 )) = 3 * ( 2 * 1 ) = 3 * ( 2 ) = 3 * 2 = 6 With only one slight caveat \u2013 negative integers are not handled. Bottom \u00b6 \\bot \\bot or bottom refers to computations that either failed to successfully complete or do not terminate; it corresponds to false in logic. Partial functions also may return bottom. To avoid throwing exceptions and bottom values, the Maybe datatype comes in useful. data Maybe a = Nothing | Just a To understand recursion scroll to the top of this page.","title":"Recursion"},{"location":"8-recursion/notes/#recursion","text":"To understand recursion scroll to the bottom of this page. Recursion refers to defining a function with regard to itself using self-referential expressions \u2013 the function will keep on calling itself unless some condition is reached, or else it never terminates (theoretically). Lambda calculus do not have recursion since expressions are nameless and so cannot be called. But to achieve Turing completeness, one needs to be able to write recursive functions. The Y combinator or fixed-point combinator is used to write recursive functions in lambda calculus.","title":"Recursion"},{"location":"8-recursion/notes/#factorial","text":"Broken Factorial A na\u00efve implementation of the factorial function may be: brokenFactorial :: Integer -> Integer brokenFactorial n = n * brokenFactorial ( n - 1 ) But trying to apply this function to any integer never terminates... brokenFactorial 3 = 3 * ( 3 - 1 ) * (( 3 - 1 ) - 1 ) * ... Because this implementation has No Base Case\u2122 . Better Factorial A better implementation for factorial may be: factorial :: Integer -> Integer factorial 0 = 1 factorial n = n * factorial ( n - 1 ) Which will terminate because eventually the base case will be reached and no more calls to itself will be made. factorial 3 = 3 * ( factorial 2 ) = 3 * ( 2 * ( factorial 1 )) = 3 * ( 2 * ( 1 * ( factorial 0 ))) = 3 * ( 2 * ( 1 * ( 1 ))) = 3 * ( 2 * ( 1 * 1 )) = 3 * ( 2 * ( 1 )) = 3 * ( 2 * 1 ) = 3 * ( 2 ) = 3 * 2 = 6 With only one slight caveat \u2013 negative integers are not handled.","title":"Factorial"},{"location":"8-recursion/notes/#bottom","text":"\\bot \\bot or bottom refers to computations that either failed to successfully complete or do not terminate; it corresponds to false in logic. Partial functions also may return bottom. To avoid throwing exceptions and bottom values, the Maybe datatype comes in useful. data Maybe a = Nothing | Just a To understand recursion scroll to the top of this page.","title":"Bottom"},{"location":"9-lists/notes/","text":"Lists \u00b6 Haskell List s serve to: Represent a collection of values. Represent an infinite series of values (a stream of values). List Datatype \u00b6 data [] a = [] | a : [ a ] Here [] is the empty list, and ( : ) is the cons operator which attaches some element a into the front of a list [ a ] . Pattern Matching \u00b6 Matching head of list: head' :: [ a ] -> Maybe a head' [] = Nothing head' ( x : _ ) = Just x -- head element x is matched with rest of list discarded Matching tail of list: tail' :: [ a ] -> Maybe [ a ] tail' [] = Nothing tail' ( _ : [] ) = Nothing tail' ( _ : xs ) = Just xs Syntatic Sugar \u00b6 A list literal is used as aList = [ 1 , 2 , 3 , 4 ] ++ [ 5 ] Which is syntactic sugar for ( 1 : 2 : 3 : 4 : [] ) ++ ( 5 : [] ) Cons cells are List's second data constructor a : [ a ] . Spine nests cons cells. Ranges \u00b6 [ 1 .. 10 ] == [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] [ 2 , 4 .. 10 ] == [ 2 , 4 , 6 , 8 , 10 ] [ 'a' .. 'c' ] = [ 'a' , 'b' , 'c' ] Such range operator (with optional step) are syntatic sugar for instances of Enum typeclass, namely for: enumFrom :: Enum a => a -> [ a ] (step omitted). enumFromThen :: Enum a => a -> a -> [ a ] (step included). enumFromTo :: Enum a => a -> a -> [ a ] (step included). enumFromThenTo :: Enum a => a -> a -> -> a -> [ a ] (step included). List Operations \u00b6 Take \u00b6 take :: Int -> [ a ] -> [ a ] take keeps the first n n elements of a list, as specified with the Int argument, and discards the rest of the list. Drop \u00b6 drop :: Int -> [ a ] -> [ a ] drop drops the first n n elements of a list, as specified with the Int argument, and keeps the rest of the list. Split At \u00b6 splitAt :: Int -> [ a ] -> ([ a ], [ a ]) splitAt partitions a list into two portions at the supplied position provided by the Int argument. Take While \u00b6 takeWhile :: ( a -> Bool ) -> [ a ] -> [ a ] takeWhile keeps the elements of the input list until it encounters an item which fails to satisfy the predicate ( a -> Bool ) . Drop While \u00b6 dropWhile :: ( a -> Bool ) -> [ a ] -> [ a ] dropWhile discards elements of the input list until it encounters an item which fails to satisfy the predicate ( a -> Bool ) . List Comprehension \u00b6 A list comprehension generates a new list from a list or lists. A generator list is required to provide input, with optional conditions to select which elements are included and/or how to map elements from input list to the generated list. Simple list comprehension squared = [ x ^ 2 | x <- [ 1 .. 10 ] ] == [ 1 , 4 , 9 , 16 , 25 , 36 , 49 , 64 , 81 , 100 ] x ^ 2 is the output function which is applied to each element of the input list to generate each element of the output list. The pipe | separates output function and input. [ 1 .. 10 ] is the input list: From a list of 1 to 10 , Take (as designated by operator <- ) each element and bind it to the name x . List comprehension with predicate evenSquared = [ x ^ 2 | x <- [ 1 .. 10 ], x ` mod ` 2 == 0 ] == [ 4 , 16 , 36 , 64 , 100 ] An additional predicate is added here x mod 2 == 0 which checks if each supplied input bound to x is an even number; if the condition succeeds, the input is kept and otherwise filtered off. List comprehension from multiple input list [ x ^ y | x <- [ 1 .. 5 ], y <- [ 2 .. 3 ] ] == [ 1 , 1 , 4 , 8 , 9 , 27 , 16 , 64 , 25 , 125 ] Notice that the rightmost generator y <- [ 2 .. 3 ] is exhausted first, then the second rightmost, etc. Spines and Non-strict Evaluation \u00b6 Haskell's List definition is recursive by nature. A spine is the connective structure which ties the collection of values together. 1 : 2 : 3 : [] == [ 1 , 2 , 3 ] : / \\ 1 : / \\ 2 : / \\ 3 [] Evaluation of the list proceeds down the spine but construction proceeds up the spine. sprint GHCi has the : sprint which can be used to print variables to see what has already been evaluated; underscores represent values not yet evaluated. Sometimes GHC introduce preemptive strictness for optimization purposes, and polymorphism for cases such as Num a => a may need the argument in order for it to be concrete; it may show up as underscore unless a more concrete type is supplied. Sprint and List Upon definition, the list is not evaluated as it is not necessary. Prelude > let blah = enumFrontTo 'a' 'z' Prelude > : sprint blah blah = _ Upon taking one element, the list is evaluated from its topmost spine and the outmost cons cell is evaluated. Prelude > take 1 blah \"a\" Prelude > : sprint blah blah = 'a' : _ Upon taking the second element, the second cons cell is evaluated which yields the second value. Prelude > take 2 blah \"ab\" Prelude > : sprint blah blah = 'a' : 'b' : _ Length When length is applied to a list, only the spine part is evaluated but not the elements (not the contained values). But sprint shows the list as if all cons cells are evaluated which is not the case. Spines evaluated independently from values Haskell values are reduced to Weak Head Normal Form (WHNF) by default. It means that expressions are only reduced as far as necessary to reach a data constructor. WHNF is a superset of NF (normal form) in that WHNF can contain both partially reduced expressions (to a data constructor or lambda) and fully reduced expressions (i.e. normal form). Length is strict on spine Given some list such as [ 1 , 2 , 3 ] and if length is applied to it, then the full spine will be evaluated but not the values contained within the cons cells: : / \\ _ : / \\ _ : / \\ _ [] If the list contained a bottom value, i.e. undefined , applying length to the list will not cause a crash precisely because the values are not evaluated. List Transformation \u00b6 Map \u00b6 map can be used to uniformly apply some function to each member of a list (which creates a new list). fmap is a more generic version of map which works for all instances of Functor (for which list is an instance of). map :: ( a -> b ) -> [ a ] -> [ b ] fmap :: Functor f => ( a -> b ) -> f a -> f b Notice that map is a higher-order function which takes a transformation function of type a -> b , which transform an element from the input list of type a into an element of the output list of type b . Of course, a and b do not necessarily have to be of distinct types. map is defined as map :: ( a -> b ) -> [ a ] -> [ b ] map _ [] = [] map f ( x : xs ) = f x : map f xs Here map simply returns an empty list if the input list is empty. Otherwise, map destructures the input list into its head element x and the rest as the list xs . It applies the transformation function f to the head element x , then cons the result f x to the result of recursively applying map to the remaining items. Filter \u00b6 filter takes an input list and a predicate, and returns a new list consisting of elements from the input list which passes the predicate check. Simple filter example Prelude > filter even [ 1 .. 10 ] [ 2 , 4 , 6 , 8 , 10 ] filter :: ( a -> Bool ) -> [ a ] -> [ a ] filter _ [] = [] filter predicate ( x : xs ) | predicate x = x : filter predicate xs | otherwise = filter predicate xs As from the definition, filter builds a new list from the input list and omits elements from the input list which do not pass the predicate check. Zipping \u00b6 Lists can be zipped together to form a single list. zip :: [ a ] -> [ b ] -> [( a , b )] Which simply takes two input lists, and builds a new list by combining pairs of elements from [ a ] and [ b ] . Zipping list Prelude > zip [ 1 , 2 , 3 ] [ 4 , 5 , 6 ] [( 1 , 4 ), ( 2 , 5 ), ( 3 , 6 )] Zip stops when it runs of out of elements If either of the input list has less elements, zip will only combine up to the shorter of the two. Prelude > zip [ 1 , 2 ] [ 4 , 5 , 6 ] [( 1 , 4 ), ( 2 , 5 )] unzip can be used to recover the original lists (or up to the length of the shorter of the original lists). unzip :: [( a , b )] -> ([ a ], [ b ]) zipWith can be used to apply a combining function: zipWith :: ( a -> b -> c ) -> [ a ] -> [ b ] -> [ c ] The combining function takes an element from either input lists, a and b , and returns a combined value of type c .","title":"Lists"},{"location":"9-lists/notes/#lists","text":"Haskell List s serve to: Represent a collection of values. Represent an infinite series of values (a stream of values).","title":"Lists"},{"location":"9-lists/notes/#list-datatype","text":"data [] a = [] | a : [ a ] Here [] is the empty list, and ( : ) is the cons operator which attaches some element a into the front of a list [ a ] .","title":"List Datatype"},{"location":"9-lists/notes/#pattern-matching","text":"Matching head of list: head' :: [ a ] -> Maybe a head' [] = Nothing head' ( x : _ ) = Just x -- head element x is matched with rest of list discarded Matching tail of list: tail' :: [ a ] -> Maybe [ a ] tail' [] = Nothing tail' ( _ : [] ) = Nothing tail' ( _ : xs ) = Just xs","title":"Pattern Matching"},{"location":"9-lists/notes/#syntatic-sugar","text":"A list literal is used as aList = [ 1 , 2 , 3 , 4 ] ++ [ 5 ] Which is syntactic sugar for ( 1 : 2 : 3 : 4 : [] ) ++ ( 5 : [] ) Cons cells are List's second data constructor a : [ a ] . Spine nests cons cells.","title":"Syntatic Sugar"},{"location":"9-lists/notes/#ranges","text":"[ 1 .. 10 ] == [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] [ 2 , 4 .. 10 ] == [ 2 , 4 , 6 , 8 , 10 ] [ 'a' .. 'c' ] = [ 'a' , 'b' , 'c' ] Such range operator (with optional step) are syntatic sugar for instances of Enum typeclass, namely for: enumFrom :: Enum a => a -> [ a ] (step omitted). enumFromThen :: Enum a => a -> a -> [ a ] (step included). enumFromTo :: Enum a => a -> a -> [ a ] (step included). enumFromThenTo :: Enum a => a -> a -> -> a -> [ a ] (step included).","title":"Ranges"},{"location":"9-lists/notes/#list-operations","text":"","title":"List Operations"},{"location":"9-lists/notes/#take","text":"take :: Int -> [ a ] -> [ a ] take keeps the first n n elements of a list, as specified with the Int argument, and discards the rest of the list.","title":"Take"},{"location":"9-lists/notes/#drop","text":"drop :: Int -> [ a ] -> [ a ] drop drops the first n n elements of a list, as specified with the Int argument, and keeps the rest of the list.","title":"Drop"},{"location":"9-lists/notes/#split-at","text":"splitAt :: Int -> [ a ] -> ([ a ], [ a ]) splitAt partitions a list into two portions at the supplied position provided by the Int argument.","title":"Split At"},{"location":"9-lists/notes/#take-while","text":"takeWhile :: ( a -> Bool ) -> [ a ] -> [ a ] takeWhile keeps the elements of the input list until it encounters an item which fails to satisfy the predicate ( a -> Bool ) .","title":"Take While"},{"location":"9-lists/notes/#drop-while","text":"dropWhile :: ( a -> Bool ) -> [ a ] -> [ a ] dropWhile discards elements of the input list until it encounters an item which fails to satisfy the predicate ( a -> Bool ) .","title":"Drop While"},{"location":"9-lists/notes/#list-comprehension","text":"A list comprehension generates a new list from a list or lists. A generator list is required to provide input, with optional conditions to select which elements are included and/or how to map elements from input list to the generated list. Simple list comprehension squared = [ x ^ 2 | x <- [ 1 .. 10 ] ] == [ 1 , 4 , 9 , 16 , 25 , 36 , 49 , 64 , 81 , 100 ] x ^ 2 is the output function which is applied to each element of the input list to generate each element of the output list. The pipe | separates output function and input. [ 1 .. 10 ] is the input list: From a list of 1 to 10 , Take (as designated by operator <- ) each element and bind it to the name x . List comprehension with predicate evenSquared = [ x ^ 2 | x <- [ 1 .. 10 ], x ` mod ` 2 == 0 ] == [ 4 , 16 , 36 , 64 , 100 ] An additional predicate is added here x mod 2 == 0 which checks if each supplied input bound to x is an even number; if the condition succeeds, the input is kept and otherwise filtered off. List comprehension from multiple input list [ x ^ y | x <- [ 1 .. 5 ], y <- [ 2 .. 3 ] ] == [ 1 , 1 , 4 , 8 , 9 , 27 , 16 , 64 , 25 , 125 ] Notice that the rightmost generator y <- [ 2 .. 3 ] is exhausted first, then the second rightmost, etc.","title":"List Comprehension"},{"location":"9-lists/notes/#spines-and-non-strict-evaluation","text":"Haskell's List definition is recursive by nature. A spine is the connective structure which ties the collection of values together. 1 : 2 : 3 : [] == [ 1 , 2 , 3 ] : / \\ 1 : / \\ 2 : / \\ 3 [] Evaluation of the list proceeds down the spine but construction proceeds up the spine. sprint GHCi has the : sprint which can be used to print variables to see what has already been evaluated; underscores represent values not yet evaluated. Sometimes GHC introduce preemptive strictness for optimization purposes, and polymorphism for cases such as Num a => a may need the argument in order for it to be concrete; it may show up as underscore unless a more concrete type is supplied. Sprint and List Upon definition, the list is not evaluated as it is not necessary. Prelude > let blah = enumFrontTo 'a' 'z' Prelude > : sprint blah blah = _ Upon taking one element, the list is evaluated from its topmost spine and the outmost cons cell is evaluated. Prelude > take 1 blah \"a\" Prelude > : sprint blah blah = 'a' : _ Upon taking the second element, the second cons cell is evaluated which yields the second value. Prelude > take 2 blah \"ab\" Prelude > : sprint blah blah = 'a' : 'b' : _ Length When length is applied to a list, only the spine part is evaluated but not the elements (not the contained values). But sprint shows the list as if all cons cells are evaluated which is not the case. Spines evaluated independently from values Haskell values are reduced to Weak Head Normal Form (WHNF) by default. It means that expressions are only reduced as far as necessary to reach a data constructor. WHNF is a superset of NF (normal form) in that WHNF can contain both partially reduced expressions (to a data constructor or lambda) and fully reduced expressions (i.e. normal form). Length is strict on spine Given some list such as [ 1 , 2 , 3 ] and if length is applied to it, then the full spine will be evaluated but not the values contained within the cons cells: : / \\ _ : / \\ _ : / \\ _ [] If the list contained a bottom value, i.e. undefined , applying length to the list will not cause a crash precisely because the values are not evaluated.","title":"Spines and Non-strict Evaluation"},{"location":"9-lists/notes/#list-transformation","text":"","title":"List Transformation"},{"location":"9-lists/notes/#map","text":"map can be used to uniformly apply some function to each member of a list (which creates a new list). fmap is a more generic version of map which works for all instances of Functor (for which list is an instance of). map :: ( a -> b ) -> [ a ] -> [ b ] fmap :: Functor f => ( a -> b ) -> f a -> f b Notice that map is a higher-order function which takes a transformation function of type a -> b , which transform an element from the input list of type a into an element of the output list of type b . Of course, a and b do not necessarily have to be of distinct types. map is defined as map :: ( a -> b ) -> [ a ] -> [ b ] map _ [] = [] map f ( x : xs ) = f x : map f xs Here map simply returns an empty list if the input list is empty. Otherwise, map destructures the input list into its head element x and the rest as the list xs . It applies the transformation function f to the head element x , then cons the result f x to the result of recursively applying map to the remaining items.","title":"Map"},{"location":"9-lists/notes/#filter","text":"filter takes an input list and a predicate, and returns a new list consisting of elements from the input list which passes the predicate check. Simple filter example Prelude > filter even [ 1 .. 10 ] [ 2 , 4 , 6 , 8 , 10 ] filter :: ( a -> Bool ) -> [ a ] -> [ a ] filter _ [] = [] filter predicate ( x : xs ) | predicate x = x : filter predicate xs | otherwise = filter predicate xs As from the definition, filter builds a new list from the input list and omits elements from the input list which do not pass the predicate check.","title":"Filter"},{"location":"9-lists/notes/#zipping","text":"Lists can be zipped together to form a single list. zip :: [ a ] -> [ b ] -> [( a , b )] Which simply takes two input lists, and builds a new list by combining pairs of elements from [ a ] and [ b ] . Zipping list Prelude > zip [ 1 , 2 , 3 ] [ 4 , 5 , 6 ] [( 1 , 4 ), ( 2 , 5 ), ( 3 , 6 )] Zip stops when it runs of out of elements If either of the input list has less elements, zip will only combine up to the shorter of the two. Prelude > zip [ 1 , 2 ] [ 4 , 5 , 6 ] [( 1 , 4 ), ( 2 , 5 )] unzip can be used to recover the original lists (or up to the length of the shorter of the original lists). unzip :: [( a , b )] -> ([ a ], [ b ]) zipWith can be used to apply a combining function: zipWith :: ( a -> b -> c ) -> [ a ] -> [ b ] -> [ c ] The combining function takes an element from either input lists, a and b , and returns a combined value of type c .","title":"Zipping"},{"location":"misc/y-combinator/","text":"Y Combinator \u00b6 Notes on Y combinator from mvanier . Explicit Recursion \u00b6 Pure lambda calculus do not have named expressions. And so one cannot call some function with its name (because it does not have a name) to achieve explicit recursion . However, implicit recursion is possible through the means of using Y combinator(s). Y Combinator Basics \u00b6 The Y combinator is: A higher-order function: Takes a single non-recursive function. Returns a version of it which is recursive. That is, it generates recursive functions from non-recursive functions. This means that programming language definitions do not have to explicitly support recursion! There are infinite number of Y combinators but only one lazy and one strict Y combinators will be discussed: Lazy Y combinator is known as the normal-order Y combinator . Strict Y combinator is known as the applicative-order Y combinator . Lazy Evaluation vs Strict Evaluation \u00b6 Lazy evaluation: Only evaluating as much of the expression as necessary to get the final result. Strict evaluation: All of the expression will be evaluated before the overall value is determined. Static Typing vs Dynamic Typing \u00b6 It is easier to define a Y combinator for dynamically strong typed languages, which is the Y combinator defined here. Combinator \u00b6 A combinator is a lambda expression with no free variables . Given some factorial function ( define factorial ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( factorial ( - n 1 )))))) In terms of its lambda expression ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( factorial ( - n 1 ))))) Is not a combinator because there are free variables: = * factorial - (Also the numbers are not even considered.) To convert this into a combinator, we need to abstract out offending free variables. First of all, the recursive call to factorial needs to be pulled out: ( define almost-factorial ( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 ))))))) With the recursive parts extracted, the yet-to-be-defined Y combinator can be used to add in recursion in the necessary place: ( define factorial ( Y almost-factorial )) Assume there is some working factorial function factorialA . ( define factorialB ( almost-factorial factorialA )) If factorialA is substituted in, ( define factorialB (( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 )))))) factorialA )) And when factorialA is substituted for f ( define factorialB ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( factorialA ( - n 1 ))) ) ) ) Which should work if factorialA works, except it does not yet exist. But if we assume factorialA to be a valid factorial function, then pass it to almost-factorial , and name the result to also be factorialA ( define factorialA ( almost-factorial factorialA )) This definition is valid iff the language uses lazy evaluation, and works! For strict evaluation though, a slightly different approach is necessary. Let there be defined several helper functions ( define identity ( lambda ( x ) x )) ( define factorial0 ( almost-factorial identity )) Notice that factorial0 is able to compute some factorials, namely the case when n = 0 n = 0 . ( factorial0 0 ) ( factorial0 0 ) ; ==> (( almost-factorial identity ) 0 ) ; ==> ( ( ( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 ))))) ) identity ) 0 ) ; ==> ( ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( identity ( - n 1 ))))) 0 ) ; ==> ( ( if ( = 0 0 ) 1 ( * 0 ( identity ( - 0 1 )))) ) ; ==> ( ( if #t 1 ( * 0 ( identity ( - 0 1 )))) ) ; ==> 1 Fibonacci fibonacci 0 = 0 fibonacci 1 = 1 fibonnaci n = fibonacci ( n - 1 ) + fibonacci ( n - 2 ) Or equivalently in Scheme ( define fibonacci ( lambda ( n ) ( cond (( = n 0 ) 0 ) (( = n 1 ) 1 ) ( else ( + ( fibonacci ( - n 1 ) ( fibonacci ( - n 2 )))))))) We can pull out the recursive function call to give an almost- version ( define almost-fibonacci ( lambda ( f ) ( lambda ( n ) ( cond (( = n 0 ) 0 ) (( = n 1 ) 1 ) ( else ( + ( f ( - n 1 ) ( f ( - n 2 )))))))))) And the Y combinator can be reused here ( define fibonacci ( Y almost-fibonacci )) Let factorial1 be defined as ( define factorial1 ( almost-factorial factorial0 )) ; which is equivalent to ( define factorial1 ( ( almost-factorial ( almost-factorial identity )) )) This will correctly compute factorials for n = 0 n = 0 and n = 1 n = 1 , but not n > 1 n > 1 . This process can be repeated: ( define factorial2 ( almost-factorial factorial1 )) ( define factorial3 ( almost-factorial factorial2 )) ( define factorial4 ( almost-factorial factorial3 )) ; ... Expanded, it looks like ( define factorial-infinity ( almost-factorial ( almost-factorial ( almost-factorial ;.... ( almost-factorial identity ) )))) Now to get it working for all n \\in \\mathbb{Z} n \\in \\mathbb{Z} , we need to repeat the chain of almost-factorial an infinite number of times; factorial-infinity is the factorial function we are looking for. If we can define an infinite chain of almost-factorial s, it will give us the desired factorial function \u2013 such factorial function is the fixpoint of almost-factorial . Fix-point of Functions \u00b6 If one keeps on trying to apply \\cos \\cos to 0 0 (i.e. \\cos (\\cos ( \\dots \\cos (0) \\dots )) \\cos (\\cos ( \\dots \\cos (0) \\dots )) ) in a calculator, one will find that it converges to approximately 0.73908513321516067 0.73908513321516067 . Applying \\cos \\cos to 0.73908513321516067 0.73908513321516067 again does not change the output ( \\cos (0.73908513321516067) \\approx 0.73908513321516067 \\cos (0.73908513321516067) \\approx 0.73908513321516067 ). Here 0.73908513321516067 0.73908513321516067 is the fix-point of the cosine function. Since the cosine function has the type \\cos :: \\mathbb{R} \\to \\mathbb{R} \\cos :: \\mathbb{R} \\to \\mathbb{R} (or of the shape a -> a where input type matches output type), it can repeatedly be applied to itself. Fixpints do not have to be numbers, so as long as the generating function has identical input/output type, and may be functions. The fixpoint function for almost-factorial shall be the function such that fixpoint-function = ( almost-factorial fixpoint-function ) Repeatedly substituting the right hand side of fixpoint-function as the input to almost-factorial , one yields fixpoint-function = ( almost-factorial ( almost-factorial fixpoint-function )) ; = ( almost-factorial ( almost-factorial ( almost-factorial fixpoint-function ))) ; = ( almost-factorial ( almost-factorial ( almost-factorial ( almost-factorial ... )))) This is in fact the desired factorial function \u2013 the fixpoint of almost-factorial is the factorial function. factorial = ( almost-factorial factorial ) ; = ( almost-factorial ( almost-factorial ( almost-factorial ( almost-factorial ... )))) Y is also the fixpoint combinator since it takes a function and returns its fixpoint. Eliminating Explicit Recursion (Lazy) \u00b6 Let Y be specified as ( Y f ) = fixpoint-of-f ( f fixpoint-of-f ) = fixpoint-of-f ( Y f ) = fixpoint-of-f = ( f fixpoint-of-f ) ( Y f ) can be substituted for fixpoint-of-f : ( Y f ) = ( f ( Y f )) Which is the definition of Y: ( define ( Y f ) ( f ( Y f ))) ; or equivalently ( define Y ( lambda ( f ) ( f ( Y f )))) Note that this definition of Y: Only works in lazy language. Not a combinator since Y in body is a free variable. Eliminating Explicit Recursion (Strict) \u00b6 In a strict language, trying to evaluate ( Y f ) would fail since ( Y f ) = ( f ( Y f )) = ( f ( f ( Y f ))) = ... But since ( Y f ) will become a function of a single argument, the equality below will hold: ( Y f ) = ( lambda ( x ) (( Y f ) x )) Which goes on to give the definition ( define Y ( lambda ( f ) ( f ( lambda ( x ) (( Y f ) x ))))) Since (lambda (x) ((Y f) x)) == (Y f) this version of Y is valid. This version will also work with strict languages because the inner ( Y f ) is contained within a lambda whose execution is delayed. Deriving the Y Combinator \u00b6 The previous versions of Y are not yet combinators since the Y in the body expressions is a free variable. Normal-order (Lazy) Y Combinator \u00b6 Given the original recursive factorial function where ( define ( factorial n ) ( if ( = n 0 ) 1 ( * n ( factorial ( - n 1 ))) ) ) To get rid of the explicit recursion, we can pass the factorial function itself as an additional argument when the function is called. ;; not working yet ( define ( part-factorial self n ) ( if ( = n 0 ) 1 ( * n ( self ( - n 1 ))) ) ) The part-factorial needs to be called differently: ( part-factorial part-factorial 5 ) == 120 This is no longerly explicitly recursive because an extra copy is sent along via self . But it needs to modified to become: ( define ( part-factorial self n ) ( if ( = n 0 ) 1 ( * n ( self self ( - n 1 ))))) Which can be rewritten as ( define ( part-factorial self ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( self self ( - n 1 )))))) Which can be invoked like (( part-factorial part-factorial ) 5 ) == 120 ( define factorial ( part-factorial part-factorial )) ( factorial 5 ) == 120 Notice that a factorial function is already defined without explicit recursion. To get it to look something like almost-factorial , the ( self self ) invocation may be extracted using a let binding. ( define ( part-factorial self ) ( let (( f ( self self ))) ( lambda ( n ) if ( = n 0 ) 1 ( * n ( f ( - n 1 )))))) Which will work in a lazy language (but not yet for a strict language; the let binding can be wrapped inside a lambda to delay execution, which will fix the infinite loop issue). Any let expression may be transformed into an equivalent lambda expression through: ( let (( x <expression_1> )) <expression_2> ) == (( lambda ( x ) <expression_2> ) <expression_1> ) Using this equality, the part-factorial can be transformed into ( define ( part-factorial self ) (( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 )))))) ( self self ))) ( define factorial ( part-factorial part-factorial )) Notice the almost-factorial contained inside: ( define almost-factorial ( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 ))))))) Which means that part-factorial can be rewritten in terms of almost-factorial : ( define part-factorial ( lambda ( self ) ( almost-factorial ( self self )))) And so the factorial function can be rewritten as: ( define factorial ( let (( part-factorial ( lambda ( self ) ( almost-factorial ( self self ))))) ( part-factorial part-factorial ))) We can rename part-factorial to x to give: ( define factorial ( let (( x ( lambda ( self ) ( almost-factorial ( self self ))))) ( x x ))) The let-to-lambda conversion technique can be used here as well: ( define factorial (( lambda ( x ) ( x x )) ( lambda ( self ) ( almost-factorial ( self self ))))) We can again rename self to x : ( define factorial (( lambda ( x ) ( x x )) ( lambda ( x ) ( almost-factorial ( x x ))))) We can change factorial into a more generic function make-recursive which makes recursive functions out of non-recursive functions: ( define ( make-recursive f ) (( lambda ( x ) ( x x )) ( lambda ( x ) ( f ( x x ))))) make-recursive is in fact the normal-order (lazy) Y combinator: ( define ( Y f ) (( lambda ( x ) ( x x )) ( lambda ( x ) ( f ( x x ))))) Which can be expanded to ( define Y ( lambda ( f ) (( lambda ( x ) ( f ( x x ))) ( lambda ( x ) ( f ( x x )))))) Applicative-order (Strict) Y Combinator \u00b6 ( define ( part-factorial self ) ( let (( f ( lambda ( y ) (( self self ) y )))) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f - n 1 )))))) Which simplies to: ( define Y ( lambda ( f ) (( lambda ( x ) ( x x )) ( lambda ( x ) ( f ( lambda ( y ) (( x x ) y ))))))) And so the factorial function can be defined as: ( define factorial ( Y almost-factorial )) An implementation of applicative-order Y-combinator in JavaScript is: const Y = f => ( x => x ( x ))( y => f ( x => y ( y )( x ))); const factorial = Y ( self => n => { if ( n == 0 ) return 1 ; else return n * self ( n - 1 ); } );","title":"Y Combinator"},{"location":"misc/y-combinator/#y-combinator","text":"Notes on Y combinator from mvanier .","title":"Y Combinator"},{"location":"misc/y-combinator/#explicit-recursion","text":"Pure lambda calculus do not have named expressions. And so one cannot call some function with its name (because it does not have a name) to achieve explicit recursion . However, implicit recursion is possible through the means of using Y combinator(s).","title":"Explicit Recursion"},{"location":"misc/y-combinator/#y-combinator-basics","text":"The Y combinator is: A higher-order function: Takes a single non-recursive function. Returns a version of it which is recursive. That is, it generates recursive functions from non-recursive functions. This means that programming language definitions do not have to explicitly support recursion! There are infinite number of Y combinators but only one lazy and one strict Y combinators will be discussed: Lazy Y combinator is known as the normal-order Y combinator . Strict Y combinator is known as the applicative-order Y combinator .","title":"Y Combinator Basics"},{"location":"misc/y-combinator/#lazy-evaluation-vs-strict-evaluation","text":"Lazy evaluation: Only evaluating as much of the expression as necessary to get the final result. Strict evaluation: All of the expression will be evaluated before the overall value is determined.","title":"Lazy Evaluation vs Strict Evaluation"},{"location":"misc/y-combinator/#static-typing-vs-dynamic-typing","text":"It is easier to define a Y combinator for dynamically strong typed languages, which is the Y combinator defined here.","title":"Static Typing vs Dynamic Typing"},{"location":"misc/y-combinator/#combinator","text":"A combinator is a lambda expression with no free variables . Given some factorial function ( define factorial ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( factorial ( - n 1 )))))) In terms of its lambda expression ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( factorial ( - n 1 ))))) Is not a combinator because there are free variables: = * factorial - (Also the numbers are not even considered.) To convert this into a combinator, we need to abstract out offending free variables. First of all, the recursive call to factorial needs to be pulled out: ( define almost-factorial ( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 ))))))) With the recursive parts extracted, the yet-to-be-defined Y combinator can be used to add in recursion in the necessary place: ( define factorial ( Y almost-factorial )) Assume there is some working factorial function factorialA . ( define factorialB ( almost-factorial factorialA )) If factorialA is substituted in, ( define factorialB (( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 )))))) factorialA )) And when factorialA is substituted for f ( define factorialB ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( factorialA ( - n 1 ))) ) ) ) Which should work if factorialA works, except it does not yet exist. But if we assume factorialA to be a valid factorial function, then pass it to almost-factorial , and name the result to also be factorialA ( define factorialA ( almost-factorial factorialA )) This definition is valid iff the language uses lazy evaluation, and works! For strict evaluation though, a slightly different approach is necessary. Let there be defined several helper functions ( define identity ( lambda ( x ) x )) ( define factorial0 ( almost-factorial identity )) Notice that factorial0 is able to compute some factorials, namely the case when n = 0 n = 0 . ( factorial0 0 ) ( factorial0 0 ) ; ==> (( almost-factorial identity ) 0 ) ; ==> ( ( ( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 ))))) ) identity ) 0 ) ; ==> ( ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( identity ( - n 1 ))))) 0 ) ; ==> ( ( if ( = 0 0 ) 1 ( * 0 ( identity ( - 0 1 )))) ) ; ==> ( ( if #t 1 ( * 0 ( identity ( - 0 1 )))) ) ; ==> 1 Fibonacci fibonacci 0 = 0 fibonacci 1 = 1 fibonnaci n = fibonacci ( n - 1 ) + fibonacci ( n - 2 ) Or equivalently in Scheme ( define fibonacci ( lambda ( n ) ( cond (( = n 0 ) 0 ) (( = n 1 ) 1 ) ( else ( + ( fibonacci ( - n 1 ) ( fibonacci ( - n 2 )))))))) We can pull out the recursive function call to give an almost- version ( define almost-fibonacci ( lambda ( f ) ( lambda ( n ) ( cond (( = n 0 ) 0 ) (( = n 1 ) 1 ) ( else ( + ( f ( - n 1 ) ( f ( - n 2 )))))))))) And the Y combinator can be reused here ( define fibonacci ( Y almost-fibonacci )) Let factorial1 be defined as ( define factorial1 ( almost-factorial factorial0 )) ; which is equivalent to ( define factorial1 ( ( almost-factorial ( almost-factorial identity )) )) This will correctly compute factorials for n = 0 n = 0 and n = 1 n = 1 , but not n > 1 n > 1 . This process can be repeated: ( define factorial2 ( almost-factorial factorial1 )) ( define factorial3 ( almost-factorial factorial2 )) ( define factorial4 ( almost-factorial factorial3 )) ; ... Expanded, it looks like ( define factorial-infinity ( almost-factorial ( almost-factorial ( almost-factorial ;.... ( almost-factorial identity ) )))) Now to get it working for all n \\in \\mathbb{Z} n \\in \\mathbb{Z} , we need to repeat the chain of almost-factorial an infinite number of times; factorial-infinity is the factorial function we are looking for. If we can define an infinite chain of almost-factorial s, it will give us the desired factorial function \u2013 such factorial function is the fixpoint of almost-factorial .","title":"Combinator"},{"location":"misc/y-combinator/#fix-point-of-functions","text":"If one keeps on trying to apply \\cos \\cos to 0 0 (i.e. \\cos (\\cos ( \\dots \\cos (0) \\dots )) \\cos (\\cos ( \\dots \\cos (0) \\dots )) ) in a calculator, one will find that it converges to approximately 0.73908513321516067 0.73908513321516067 . Applying \\cos \\cos to 0.73908513321516067 0.73908513321516067 again does not change the output ( \\cos (0.73908513321516067) \\approx 0.73908513321516067 \\cos (0.73908513321516067) \\approx 0.73908513321516067 ). Here 0.73908513321516067 0.73908513321516067 is the fix-point of the cosine function. Since the cosine function has the type \\cos :: \\mathbb{R} \\to \\mathbb{R} \\cos :: \\mathbb{R} \\to \\mathbb{R} (or of the shape a -> a where input type matches output type), it can repeatedly be applied to itself. Fixpints do not have to be numbers, so as long as the generating function has identical input/output type, and may be functions. The fixpoint function for almost-factorial shall be the function such that fixpoint-function = ( almost-factorial fixpoint-function ) Repeatedly substituting the right hand side of fixpoint-function as the input to almost-factorial , one yields fixpoint-function = ( almost-factorial ( almost-factorial fixpoint-function )) ; = ( almost-factorial ( almost-factorial ( almost-factorial fixpoint-function ))) ; = ( almost-factorial ( almost-factorial ( almost-factorial ( almost-factorial ... )))) This is in fact the desired factorial function \u2013 the fixpoint of almost-factorial is the factorial function. factorial = ( almost-factorial factorial ) ; = ( almost-factorial ( almost-factorial ( almost-factorial ( almost-factorial ... )))) Y is also the fixpoint combinator since it takes a function and returns its fixpoint.","title":"Fix-point of Functions"},{"location":"misc/y-combinator/#eliminating-explicit-recursion-lazy","text":"Let Y be specified as ( Y f ) = fixpoint-of-f ( f fixpoint-of-f ) = fixpoint-of-f ( Y f ) = fixpoint-of-f = ( f fixpoint-of-f ) ( Y f ) can be substituted for fixpoint-of-f : ( Y f ) = ( f ( Y f )) Which is the definition of Y: ( define ( Y f ) ( f ( Y f ))) ; or equivalently ( define Y ( lambda ( f ) ( f ( Y f )))) Note that this definition of Y: Only works in lazy language. Not a combinator since Y in body is a free variable.","title":"Eliminating Explicit Recursion (Lazy)"},{"location":"misc/y-combinator/#eliminating-explicit-recursion-strict","text":"In a strict language, trying to evaluate ( Y f ) would fail since ( Y f ) = ( f ( Y f )) = ( f ( f ( Y f ))) = ... But since ( Y f ) will become a function of a single argument, the equality below will hold: ( Y f ) = ( lambda ( x ) (( Y f ) x )) Which goes on to give the definition ( define Y ( lambda ( f ) ( f ( lambda ( x ) (( Y f ) x ))))) Since (lambda (x) ((Y f) x)) == (Y f) this version of Y is valid. This version will also work with strict languages because the inner ( Y f ) is contained within a lambda whose execution is delayed.","title":"Eliminating Explicit Recursion (Strict)"},{"location":"misc/y-combinator/#deriving-the-y-combinator","text":"The previous versions of Y are not yet combinators since the Y in the body expressions is a free variable.","title":"Deriving the Y Combinator"},{"location":"misc/y-combinator/#normal-order-lazy-y-combinator","text":"Given the original recursive factorial function where ( define ( factorial n ) ( if ( = n 0 ) 1 ( * n ( factorial ( - n 1 ))) ) ) To get rid of the explicit recursion, we can pass the factorial function itself as an additional argument when the function is called. ;; not working yet ( define ( part-factorial self n ) ( if ( = n 0 ) 1 ( * n ( self ( - n 1 ))) ) ) The part-factorial needs to be called differently: ( part-factorial part-factorial 5 ) == 120 This is no longerly explicitly recursive because an extra copy is sent along via self . But it needs to modified to become: ( define ( part-factorial self n ) ( if ( = n 0 ) 1 ( * n ( self self ( - n 1 ))))) Which can be rewritten as ( define ( part-factorial self ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( self self ( - n 1 )))))) Which can be invoked like (( part-factorial part-factorial ) 5 ) == 120 ( define factorial ( part-factorial part-factorial )) ( factorial 5 ) == 120 Notice that a factorial function is already defined without explicit recursion. To get it to look something like almost-factorial , the ( self self ) invocation may be extracted using a let binding. ( define ( part-factorial self ) ( let (( f ( self self ))) ( lambda ( n ) if ( = n 0 ) 1 ( * n ( f ( - n 1 )))))) Which will work in a lazy language (but not yet for a strict language; the let binding can be wrapped inside a lambda to delay execution, which will fix the infinite loop issue). Any let expression may be transformed into an equivalent lambda expression through: ( let (( x <expression_1> )) <expression_2> ) == (( lambda ( x ) <expression_2> ) <expression_1> ) Using this equality, the part-factorial can be transformed into ( define ( part-factorial self ) (( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 )))))) ( self self ))) ( define factorial ( part-factorial part-factorial )) Notice the almost-factorial contained inside: ( define almost-factorial ( lambda ( f ) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f ( - n 1 ))))))) Which means that part-factorial can be rewritten in terms of almost-factorial : ( define part-factorial ( lambda ( self ) ( almost-factorial ( self self )))) And so the factorial function can be rewritten as: ( define factorial ( let (( part-factorial ( lambda ( self ) ( almost-factorial ( self self ))))) ( part-factorial part-factorial ))) We can rename part-factorial to x to give: ( define factorial ( let (( x ( lambda ( self ) ( almost-factorial ( self self ))))) ( x x ))) The let-to-lambda conversion technique can be used here as well: ( define factorial (( lambda ( x ) ( x x )) ( lambda ( self ) ( almost-factorial ( self self ))))) We can again rename self to x : ( define factorial (( lambda ( x ) ( x x )) ( lambda ( x ) ( almost-factorial ( x x ))))) We can change factorial into a more generic function make-recursive which makes recursive functions out of non-recursive functions: ( define ( make-recursive f ) (( lambda ( x ) ( x x )) ( lambda ( x ) ( f ( x x ))))) make-recursive is in fact the normal-order (lazy) Y combinator: ( define ( Y f ) (( lambda ( x ) ( x x )) ( lambda ( x ) ( f ( x x ))))) Which can be expanded to ( define Y ( lambda ( f ) (( lambda ( x ) ( f ( x x ))) ( lambda ( x ) ( f ( x x ))))))","title":"Normal-order (Lazy) Y Combinator"},{"location":"misc/y-combinator/#applicative-order-strict-y-combinator","text":"( define ( part-factorial self ) ( let (( f ( lambda ( y ) (( self self ) y )))) ( lambda ( n ) ( if ( = n 0 ) 1 ( * n ( f - n 1 )))))) Which simplies to: ( define Y ( lambda ( f ) (( lambda ( x ) ( x x )) ( lambda ( x ) ( f ( lambda ( y ) (( x x ) y ))))))) And so the factorial function can be defined as: ( define factorial ( Y almost-factorial )) An implementation of applicative-order Y-combinator in JavaScript is: const Y = f => ( x => x ( x ))( y => f ( x => y ( y )( x ))); const factorial = Y ( self => n => { if ( n == 0 ) return 1 ; else return n * self ( n - 1 ); } );","title":"Applicative-order (Strict) Y Combinator"}]}